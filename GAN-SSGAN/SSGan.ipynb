{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnfg+yjLNEI5n61fmzl1gE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pydevcasts/MLHub/blob/master/SSGan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR3eD3ig5--A",
        "outputId": "66f9b139-0b67-4052-da29-078dd9a54d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting pytorch-fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-fid\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-fid-0.3.0 torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pytorch-fid  torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os  # For interacting with the operating system\n",
        "import torch  # Main PyTorch library\n",
        "import numpy as np  # For numerical operations\n",
        "import torch.nn as nn  # For building neural network components\n",
        "import torch.optim as optim  # For optimization algorithms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt  # For plotting images and graphs\n",
        "import torch.autograd as autograd\n",
        "from pytorch_fid import fid_score  # For calculating the Fréchet Inception Distance (FID)\n",
        "from torch.utils.data import DataLoader  # For loading data in batches\n",
        "from torchvision import datasets, transforms  # For datasets and image transformations"
      ],
      "metadata": {
        "id": "F6gdnEs46OQr"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU if available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the dimensionality of the latent space for the generator\n",
        "latent_dim = 64\n",
        "\n",
        "# Set the batch size for training\n",
        "batch_size = 128 #= [256, 128, 64, 32, 16, 8]\n",
        "\n",
        "# Define the size of the images (e.g., for MNIST, images are 28x28 pixels)\n",
        "image_size = 28\n",
        "\n",
        "# Set the learning rate for the optimizer\n",
        "lr = 0.0002\n",
        "\n",
        "# Define the number of epochs for training the model\n",
        "num_epochs = 20"
      ],
      "metadata": {
        "id": "U2Izj03I6Rlb"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a series of transformations to be applied to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),  # Resize images to the specified image size (28x28)\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.5,), (0.5,)),  # Normalize the images to have mean 0.5 and standard deviation 0.5\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Create a DataLoader for batching and shuffling the dataset\n",
        "dataloader = DataLoader(dataset,\n",
        "                        batch_size=batch_size,  # Set the batch size\n",
        "                        shuffle=True,  # Shuffle the dataset for each epoch\n",
        "                        drop_last=True  # Drop the last incomplete batch if it is smaller than batch_size\n",
        "                        )"
      ],
      "metadata": {
        "id": "PMy5x5Wp6UR0"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "### Cell 4: Define Residual Block for Generator\n",
        "class ResidualBlockG(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, upsample=True):\n",
        "        super().__init__()\n",
        "        self.upsample = upsample  # Flag to determine whether to upsample\n",
        "\n",
        "        # Define the main block of the residual block\n",
        "        self.block = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),  # Batch normalization\n",
        "            nn.ReLU(),  # ReLU activation\n",
        "            nn.Upsample(scale_factor=2, mode='nearest') if upsample else nn.Identity(),  # Upsampling if needed\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),  # First convolution\n",
        "            nn.BatchNorm2d(out_channels),  # Batch normalization\n",
        "            nn.ReLU(),  # ReLU activation\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # Second convolution\n",
        "        )\n",
        "\n",
        "        # Define the shortcut connection\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode='nearest') if upsample else nn.Identity(),  # Upsampling if needed\n",
        "            # nn.Conv2d(in_channels, out_channels, kernel_size=1)  # 1x1 convolution for matching dimensions\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Return the sum of the main block output and the shortcut connection\n",
        "        return self.block(x) + self.shortcut(x)\n",
        "\n",
        "\n",
        "### Cell 5: Implement Generator with Architecture from Table 4\n",
        "class SSGenerator(nn.Module):\n",
        "    def __init__(self, latent_dim=128):\n",
        "        super().__init__()\n",
        "        # Initial layer to project the latent vector\n",
        "        self.init_layer = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256 * 4 * 4),  # Fully connected layer to expand latent vector\n",
        "            nn.BatchNorm1d(256 * 4 * 4),  # Batch normalization\n",
        "        )\n",
        "\n",
        "        # Residual blocks to upscale and refine the generated images\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            ResidualBlockG(256, 256, upsample=True),  # First residual block\n",
        "            ResidualBlockG(256, 256, upsample=True),  # Second residual block\n",
        "            ResidualBlockG(256, 256, upsample=True),   # Third residual block\n",
        "            nn.ReLU()  # ReLU activation\n",
        "        )\n",
        "\n",
        "        # Final layers to produce the output image\n",
        "        self.final_layers = nn.Sequential(\n",
        "            # nn.BatchNorm2d(256),  # Batch normalization\n",
        "            # nn.ReLU(),  # ReLU activation\n",
        "            nn.Conv2d(256, 1, kernel_size=3, padding=1),  # Final convolution to reduce channels to 1 (grayscale image)\n",
        "            nn.Tanh()  # Tanh activation to output values in the range [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        # Forward pass through the generator\n",
        "        x = self.init_layer(z)  # Pass latent vector through initial layer\n",
        "        x = x.view(x.size(0), 256, 4, 4)  # Reshape to (batch_size, channels, height, width)\n",
        "        x = self.res_blocks(x)  # Pass through residual blocks\n",
        "        return self.final_layers(x)  # Pass through final layers to get output image"
      ],
      "metadata": {
        "id": "-M6LDlfj6wjU"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchinfo\n",
        "img = SSGenerator()\n",
        "torchinfo.summary(img,input_size=(1,128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyjUCXME655E",
        "outputId": "a65b3c03-4b69-40f4-98d2-85572230c5af"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "SSGenerator                              [1, 1, 32, 32]            --\n",
              "├─Sequential: 1-1                        [1, 4096]                 --\n",
              "│    └─Linear: 2-1                       [1, 4096]                 528,384\n",
              "│    └─BatchNorm1d: 2-2                  [1, 4096]                 8,192\n",
              "├─Sequential: 1-2                        [1, 256, 32, 32]          --\n",
              "│    └─ResidualBlockG: 2-3               [1, 256, 8, 8]            --\n",
              "│    │    └─Sequential: 3-1              [1, 256, 8, 8]            1,181,184\n",
              "│    │    └─Sequential: 3-2              [1, 256, 8, 8]            --\n",
              "│    └─ResidualBlockG: 2-4               [1, 256, 16, 16]          --\n",
              "│    │    └─Sequential: 3-3              [1, 256, 16, 16]          1,181,184\n",
              "│    │    └─Sequential: 3-4              [1, 256, 16, 16]          --\n",
              "│    └─ResidualBlockG: 2-5               [1, 256, 32, 32]          --\n",
              "│    │    └─Sequential: 3-5              [1, 256, 32, 32]          1,181,184\n",
              "│    │    └─Sequential: 3-6              [1, 256, 32, 32]          --\n",
              "│    └─ReLU: 2-6                         [1, 256, 32, 32]          --\n",
              "├─Sequential: 1-3                        [1, 1, 32, 32]            --\n",
              "│    └─Conv2d: 2-7                       [1, 1, 32, 32]            2,305\n",
              "│    └─Tanh: 2-8                         [1, 1, 32, 32]            --\n",
              "==========================================================================================\n",
              "Total params: 4,082,433\n",
              "Trainable params: 4,082,433\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 1.59\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 9.02\n",
              "Params size (MB): 16.33\n",
              "Estimated Total Size (MB): 25.35\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchinfo\n",
        "\n",
        "block = ResidualBlockG(256, 256, upsample=True)\n",
        "torchinfo.summary(block, input_size=(1, 256, 4, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_Rz6eczAQSQ",
        "outputId": "92f1bec1-7f2f-4bab-8d5c-cd1fc54a707e"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResidualBlockG                           [1, 256, 8, 8]            --\n",
              "├─Sequential: 1-1                        [1, 256, 8, 8]            --\n",
              "│    └─BatchNorm2d: 2-1                  [1, 256, 4, 4]            512\n",
              "│    └─ReLU: 2-2                         [1, 256, 4, 4]            --\n",
              "│    └─Upsample: 2-3                     [1, 256, 8, 8]            --\n",
              "│    └─Conv2d: 2-4                       [1, 256, 8, 8]            590,080\n",
              "│    └─BatchNorm2d: 2-5                  [1, 256, 8, 8]            512\n",
              "│    └─ReLU: 2-6                         [1, 256, 8, 8]            --\n",
              "│    └─Conv2d: 2-7                       [1, 256, 8, 8]            590,080\n",
              "├─Sequential: 1-2                        [1, 256, 8, 8]            --\n",
              "│    └─Upsample: 2-8                     [1, 256, 8, 8]            --\n",
              "==========================================================================================\n",
              "Total params: 1,181,184\n",
              "Trainable params: 1,181,184\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 75.53\n",
              "==========================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 0.43\n",
              "Params size (MB): 4.72\n",
              "Estimated Total Size (MB): 5.17\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# تعریف بلوک Residual برای Discriminator\n",
        "class ResidualBlockD(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample=False):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample  # Flag to determine if this is the first block\n",
        "\n",
        "        # Block1\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.ReLU() if not downsample else nn.Identity(),  # ReLU (not for the first block)\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),  # Conv2D 3x3\n",
        "            nn.utils.spectral_norm(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)),  # Spectral Norm\n",
        "            nn.ReLU(),  # ReLU\n",
        "        )\n",
        "\n",
        "        # Block2\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),  # Conv2D 3x3\n",
        "            nn.utils.spectral_norm(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)),  # Spectral Norm\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),  # AvgPool2D 2x2\n",
        "        )\n",
        "\n",
        "        # Shortcut connection\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),  # Conv2D 1x1\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),  # AvgPool2D 2x2\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block1\n",
        "        out1 = self.block1(x)\n",
        "\n",
        "        # Block2\n",
        "        out2 = self.block2(out1)\n",
        "\n",
        "        # Shortcut connection\n",
        "        shortcut = self.shortcut(x)\n",
        "\n",
        "        # Combine Block1 + Block2 with shortcut\n",
        "        return out2 + shortcut\n",
        "\n",
        "\n",
        "# تعریف Discriminator برای SSGAN\n",
        "class SSDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Residual blocks to downsample and refine the input images\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            ResidualBlockD(1, 128, downsample=True),  # First residual block (downsample)\n",
        "            ResidualBlockD(128, 128),  # Second residual block (downsample)\n",
        "            ResidualBlockD(128, 128),  # Third residual block (no downsample)\n",
        "            ResidualBlockD(128, 128),  # Fourth residual block (no downsample)\n",
        "        )\n",
        "\n",
        "        # Final layers to produce the output\n",
        "        self.final_layers = nn.Sequential(\n",
        "            nn.Linear(128 * 3 * 3, 1),  # Fully connected layer to output a single value (real/fake)\n",
        "            nn.Linear(128 * 3 * 3, 4),  # Fully connected layer for self-supervised task (e.g., rotation prediction)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the discriminator\n",
        "        x = self.res_blocks(x)  # Pass through residual blocks\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        real_fake_output = self.final_layers[0](x)  # Output for real/fake classification\n",
        "        self_supervised_output = self.final_layers[1](x)  # Output for self-supervised task\n",
        "        return real_fake_output, self_supervised_output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4YQWPJquBTph"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Summary for ResidualBlockD:\")\n",
        "residual_block = ResidualBlockD(in_channels=1, out_channels=128, downsample=False)\n",
        "torchinfo.summary(residual_block, input_size=(128, 1, 28, 28))  # ورودی با ابعاد (batch_size, channels, height, width)\n",
        "\n",
        "# نمایش خلاصه‌ی SSDiscriminator\n",
        "print(\"\\nSummary for SSDiscriminator:\")\n",
        "discriminator = SSDiscriminator()\n",
        "torchinfo.summary(discriminator, input_size=(128, 1, 28, 28))  # ورودی با ابعاد (batch_size, channels, height, width)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgHDrKToOAHk",
        "outputId": "009570b4-9117-450b-93ca-f13def21ef18"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for ResidualBlockD:\n",
            "\n",
            "Summary for SSDiscriminator:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "SSDiscriminator                          [128, 1]                  --\n",
              "├─Sequential: 1-1                        [128, 128, 3, 3]          --\n",
              "│    └─ResidualBlockD: 2-1               [128, 128, 15, 15]        --\n",
              "│    │    └─Sequential: 3-1              [128, 128, 28, 28]        148,864\n",
              "│    │    └─Sequential: 3-2              [128, 128, 15, 15]        295,168\n",
              "│    │    └─Sequential: 3-3              [128, 128, 15, 15]        256\n",
              "│    └─ResidualBlockD: 2-2               [128, 128, 8, 8]          --\n",
              "│    │    └─Sequential: 3-4              [128, 128, 15, 15]        295,168\n",
              "│    │    └─Sequential: 3-5              [128, 128, 8, 8]          295,168\n",
              "│    │    └─Sequential: 3-6              [128, 128, 8, 8]          16,512\n",
              "│    └─ResidualBlockD: 2-3               [128, 128, 5, 5]          --\n",
              "│    │    └─Sequential: 3-7              [128, 128, 8, 8]          295,168\n",
              "│    │    └─Sequential: 3-8              [128, 128, 5, 5]          295,168\n",
              "│    │    └─Sequential: 3-9              [128, 128, 5, 5]          16,512\n",
              "│    └─ResidualBlockD: 2-4               [128, 128, 3, 3]          --\n",
              "│    │    └─Sequential: 3-10             [128, 128, 5, 5]          295,168\n",
              "│    │    └─Sequential: 3-11             [128, 128, 3, 3]          295,168\n",
              "│    │    └─Sequential: 3-12             [128, 128, 3, 3]          16,512\n",
              "├─Sequential: 1-2                        --                        --\n",
              "│    └─Linear: 2-5                       [128, 1]                  1,153\n",
              "│    └─Linear: 2-6                       [128, 4]                  4,612\n",
              "==========================================================================================\n",
              "Total params: 2,270,597\n",
              "Trainable params: 2,270,597\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 46.86\n",
              "==========================================================================================\n",
              "Input size (MB): 0.40\n",
              "Forward/backward pass size (MB): 719.59\n",
              "Params size (MB): 9.08\n",
              "Estimated Total Size (MB): 729.07\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# تعریف Generator و Discriminator (با استفاده از کدهای قبلی)\n",
        "generator = SSGenerator(latent_dim=128).to(device)\n",
        "discriminator = SSDiscriminator().to(device)\n",
        "\n",
        "# تعریف بهینه‌سازها\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# تعریف توابع خطا\n",
        "criterion = nn.BCEWithLogitsLoss()  # برای تشخیص واقعی/جعلی\n",
        "criterion_ss = nn.CrossEntropyLoss()  # برای وظیفه خودنظارتی (مثلاً پیش‌بینی چرخش)\n"
      ],
      "metadata": {
        "id": "AJHZmcOonsVf"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# لیست‌ها برای ذخیره Loss‌ها\n",
        "g_losses = []\n",
        "d_losses = []\n",
        "\n",
        "# آموزش مدل\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_images, _) in enumerate(dataloader):\n",
        "        real_images = real_images.to(device)\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # (a) Train Discriminator\n",
        "        discriminator.zero_grad()\n",
        "\n",
        "        # 1. Train with real images\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # Discriminator output for real images\n",
        "        real_output, real_ss_output = discriminator(real_images)\n",
        "        d_loss_real = criterion(real_output, real_labels)\n",
        "\n",
        "        # 2. Train with fake images\n",
        "        z = torch.randn(batch_size, 128).to(device)  # Sample random latent vectors\n",
        "        fake_images = generator(z)\n",
        "        fake_output, fake_ss_output = discriminator(fake_images.detach())\n",
        "        d_loss_fake = criterion(fake_output, fake_labels)\n",
        "\n",
        "        # 3. Self-supervised task (e.g., rotation prediction)\n",
        "        # Assuming rotation prediction with 4 classes (0°, 90°, 180°, 270°)\n",
        "        rotation_labels = torch.randint(0, 4, (batch_size,)).to(device)\n",
        "        d_loss_ss = criterion_ss(real_ss_output, rotation_labels)\n",
        "\n",
        "        # Total discriminator loss\n",
        "        d_loss = d_loss_real + d_loss_fake + d_loss_ss\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # (b) Train Generator\n",
        "        generator.zero_grad()\n",
        "\n",
        "        # Generate fake images again\n",
        "        z = torch.randn(batch_size, 128).to(device)\n",
        "        fake_images = generator(z)\n",
        "        fake_output, _ = discriminator(fake_images)\n",
        "\n",
        "        # Generator loss\n",
        "        g_loss = criterion(fake_output, real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ذخیره Loss‌ها\n",
        "        g_losses.append(g_loss.item())\n",
        "        d_losses.append(d_loss.item())\n",
        "\n",
        "        # Print losses every 100 steps\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], \"\n",
        "                  f\"Loss_D: {d_loss.item():.4f}, Loss_G: {g_loss.item():.4f}\")\n",
        "\n",
        "    # Save generated images at the end of each epoch\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(100, 128).to(device)  # Generate 100 random latent vectors\n",
        "            generated_images = generator(z).cpu()  # Generate images and move to CPU\n",
        "\n",
        "            # Save generated images\n",
        "            fig, axs = plt.subplots(10, 10, figsize=(10, 10))\n",
        "            for i in range(10):\n",
        "                for j in range(10):\n",
        "                    img_idx = i * 10 + j\n",
        "                    axs[i, j].imshow(generated_images[img_idx].squeeze(), cmap='gray')\n",
        "                    axs[i, j].axis('off')\n",
        "            plt.savefig(f\"generated_images_epoch_{epoch + 1}.png\")\n",
        "            plt.close(fig)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGF2OJNlmpJs",
        "outputId": "646382cf-6391-4016-8611-c82c9e9d2f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/468], Loss_D: 1.4078, Loss_G: 6.4545\n",
            "Epoch [1/10], Step [200/468], Loss_D: 1.3863, Loss_G: 7.5723\n",
            "Epoch [1/10], Step [300/468], Loss_D: 1.3940, Loss_G: 6.5627\n",
            "Epoch [1/10], Step [400/468], Loss_D: 1.3900, Loss_G: 7.5336\n",
            "Epoch [2/10], Step [100/468], Loss_D: 1.3922, Loss_G: 7.8490\n",
            "Epoch [2/10], Step [200/468], Loss_D: 1.3893, Loss_G: 8.2349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# رسم نمودار Loss‌ها\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(g_losses, label=\"Generator Loss\")\n",
        "plt.plot(d_losses, label=\"Discriminator Loss\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.legend()\n",
        "plt.savefig(\"loss_plot.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TZXh4kQ9pr-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create real images directory\n",
        "os.makedirs(\"./real_images\", exist_ok=True)\n",
        "for i, (img, _) in enumerate(dataset):\n",
        "    if i >= 5000:\n",
        "        break\n",
        "    plt.imsave(f\"./real_images/{i}.png\", img.squeeze().numpy(), cmap='gray')\n",
        "\n",
        "\n",
        "fake_images = []\n",
        "for _ in range(100):  # 100 * batch_size = 12800 > 5000\n",
        "    z = torch.randn(batch_size, latent_dim).to(device)\n",
        "    fake = generator(z).cpu().detach()\n",
        "    print(fake.shape)\n",
        "    fake_images.append(fake)\n",
        "fake_images = torch.cat(fake_images)[:5000]  # انتخاب 5000 نمونه\n",
        "\n",
        "# ذخیره در پوشه\n",
        "os.makedirs(\"./fake_images_ssgan\", exist_ok=True)\n",
        "for i, img in enumerate(fake_images):\n",
        "    plt.imsave(f\"./fake_images_ssgan/{i}.png\", img.squeeze(), cmap='gray')\n",
        "# Verify paths\n",
        "print(f\"Real images: {len(os.listdir('./real_images'))}\")\n",
        "print(f\"Fake images: {len(os.listdir('./fake_images_ssgan'))}\")\n",
        "\n",
        "# Calculate FID\n",
        "fid_value = fid_score.calculate_fid_given_paths(\n",
        "    [\"./real_images\", \"./fake_images_ssgan\"],\n",
        "    batch_size=50,\n",
        "    device=device,\n",
        "    dims=2048\n",
        ")\n",
        "print(f\"FID Score: {fid_value:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "SA5esAJ2qmAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}