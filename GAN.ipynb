{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQWrG6QfcW6gOh+5ps86Ug",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pydevcasts/MLHub/blob/master/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WylKs0mC2pLX",
        "outputId": "06387afa-8156-41c1-b2c0-d8d486b745d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting pytorch-fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-fid\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-fid-0.3.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages: PyTorch, torchvision, and pytorch-fid for FID calculation\n",
        "!pip install torch torchvision pytorch-fid\n",
        "# Import necessary libraries\n",
        "import os  # For interacting with the operating system\n",
        "import torch  # Main PyTorch library\n",
        "import numpy as np  # For numerical operations\n",
        "import torch.nn as nn  # For building neural network components\n",
        "import torch.optim as optim  # For optimization algorithms\n",
        "import matplotlib.pyplot as plt  # For plotting images and graphs\n",
        "import torch.autograd as autograd\n",
        "from pytorch_fid import fid_score  # For calculating the Fréchet Inception Distance (FID)\n",
        "from torch.utils.data import DataLoader  # For loading data in batches\n",
        "from torchvision import datasets, transforms  # For datasets and image transformations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU if available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the dimensionality of the latent space for the generator\n",
        "latent_dim = 64\n",
        "\n",
        "# Set the batch size for training\n",
        "batch_size = 128 #= [256, 128, 64, 32, 16, 8]\n",
        "\n",
        "# Define the size of the images (e.g., for MNIST, images are 28x28 pixels)\n",
        "image_size = 28\n",
        "\n",
        "# Set the learning rate for the optimizer\n",
        "lr = 0.0002\n",
        "\n",
        "# Define the number of epochs for training the model\n",
        "num_epochs = 20"
      ],
      "metadata": {
        "id": "ipDKfij-29WF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a series of transformations to be applied to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),  # Resize images to the specified image size (28x28)\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.5,), (0.5,)),  # Normalize the images to have mean 0.5 and standard deviation 0.5\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Create a DataLoader for batching and shuffling the dataset\n",
        "dataloader = DataLoader(dataset,\n",
        "                        batch_size=batch_size,  # Set the batch size\n",
        "                        shuffle=True,  # Shuffle the dataset for each epoch\n",
        "                        drop_last=True  # Drop the last incomplete batch if it is smaller than batch_size\n",
        "                        )"
      ],
      "metadata": {
        "id": "UTq4cchJ3C3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7d4aab-9f59-49b7-92d3-618298a522ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 489kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.49MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.34MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(latent_dim)\n",
        "print(batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykO0kt0lkzdJ",
        "outputId": "6780d313-dcf9-43d0-bd27-6f0e21dea33c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Generator class, inheriting from nn.Module\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=64, img_channels=1, img_size=28):\n",
        "        super().__init__()  # Initialize the base class\n",
        "\n",
        "        # Define the model architecture as a sequential container\n",
        "        self.model = nn.Sequential(\n",
        "            # Layer 1: Map latent_dim to 512 units\n",
        "            nn.Linear(latent_dim, 512),  # Fully connected layer from latent space to 512 units\n",
        "            nn.BatchNorm1d(512),  # Batch normalization for stable training\n",
        "            nn.ReLU(),  # ReLU activation function\n",
        "\n",
        "            # Layer 2: Map 512 units to 64*8*8 units\n",
        "            nn.Linear(512, 64 * 8 * 8),  # Fully connected layer to 64*8*8 units\n",
        "            nn.BatchNorm1d(64 * 8 * 8),  # Batch normalization\n",
        "            nn.ReLU(),  # ReLU activation function\n",
        "\n",
        "            # Reshape to 3D tensor for convolutional layers\n",
        "            nn.Unflatten(1, (64, 8, 8)),  # Reshape the output to (batch_size, 64, 8, 8)\n",
        "\n",
        "            # First PixelShuffle: Upsample (64, 8, 8) to (16, 16, 16)\n",
        "            nn.PixelShuffle(2),  # Rearranges elements in the tensor to increase spatial dimensions\n",
        "\n",
        "            # Convolutional layer: Increase channels from 16 to 32\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # 2D convolution with 32 output channels\n",
        "            nn.BatchNorm2d(32),  # Batch normalization\n",
        "            nn.ReLU(),  # ReLU activation function\n",
        "\n",
        "            # Second PixelShuffle: Upsample (32, 16, 16) to (8, 32, 32)\n",
        "            nn.PixelShuffle(2),  # Further increases spatial dimensions while reducing channels\n",
        "\n",
        "            # Final layers to produce the output image\n",
        "            nn.Conv2d(8, img_channels, kernel_size=3, padding=1),  # Final convolution to produce the desired number of channels (e.g., 1 for grayscale)\n",
        "            nn.Upsample(size=(img_size, img_size), mode='bilinear'),  # Upsample to the final image size (28x28)\n",
        "            nn.Sigmoid()  # Sigmoid activation to output values between 0 and 1 for pixel intensities\n",
        "        )\n",
        "\n",
        "    # Forward pass through the generator\n",
        "    def forward(self, z):\n",
        "        return self.model(z)  # Pass the input through the model"
      ],
      "metadata": {
        "id": "UR03M1Ph3Ptq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(latent_dim)\n",
        "print(batch_size)\n",
        "# print(real_images.size(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rZG5kklk4q1",
        "outputId": "c68be8e4-a28f-473a-82af-20d489998301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the Discriminator class, inheriting from nn.Module\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()  # Initialize the base class\n",
        "\n",
        "        # Define the model architecture as a sequential container\n",
        "        self.main = nn.Sequential(\n",
        "            # First convolutional layer: 1 input channel -> 32 output channels\n",
        "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),  # Output size: 32x14x14\n",
        "            nn.ReLU(),  # ReLU activation function\n",
        "\n",
        "            # Second convolutional layer: 32 input channels -> 64 output channels\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),  # Output size: 64x7x7\n",
        "            nn.ReLU(),  # ReLU activation function\n",
        "\n",
        "            # Flatten the output for the fully connected layers\n",
        "            nn.Flatten(),  # Convert the 3D tensor to a 1D tensor\n",
        "\n",
        "            # First fully connected layer: 64*7*7 inputs -> 512 outputs\n",
        "            nn.Linear(64 * 7 * 7, 512),  # The input size must match the flattened output\n",
        "            nn.ReLU(),  # ReLU activation function\n",
        "\n",
        "            # Second fully connected layer: 512 inputs -> 1 output\n",
        "            nn.Linear(512, 1),  # Final layer outputs a single value (real or fake)\n",
        "\n",
        "            # Sigmoid activation to output a probability between 0 and 1\n",
        "            nn.Sigmoid()  # This is used to produce a probability score for the input\n",
        "        )\n",
        "\n",
        "    # Forward pass through the discriminator\n",
        "    def forward(self, x):\n",
        "        return self.main(x)  # Pass the input through the model"
      ],
      "metadata": {
        "id": "tmGM7Hq33Yhi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(latent_dim)\n",
        "print(batch_size)\n",
        "# print(real_images.size(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jET-HWOCk7q2",
        "outputId": "bc91fbf7-edd3-422f-aa35-4c272fe0b661"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### تابع خطا (Non-Saturating Loss):"
      ],
      "metadata": {
        "id": "itZTYN9TzqCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss functions for the generator and discriminator\n",
        "def generator_loss(fake_output):\n",
        "    # Non-saturating loss for the generator\n",
        "    return -torch.mean(torch.log(fake_output))\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    # Non-saturating loss for the discriminator\n",
        "    real_loss = -torch.mean(torch.log(real_output))  # Loss for real images\n",
        "    fake_loss = -torch.mean(torch.log(1 - fake_output))  # Loss for fake images\n",
        "    return real_loss + fake_loss  # Total loss for the discriminator\n",
        "\n",
        "# Initialize the generator and discriminator models and move them to the specified device (GPU or CPU)\n",
        "generator = Generator().to(device)  # Create and move the generator to the device\n",
        "discriminator = Discriminator().to(device)  # Create and move the discriminator to the device\n",
        "\n",
        "# Initialize optimizers for both models\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))  # Adam optimizer for the generator\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))  # Adam optimizer for the discriminator"
      ],
      "metadata": {
        "id": "aeEZjWqh3bKo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 7. Training Loop\n",
        "g_losses = []  # List to store generator loss values\n",
        "d_losses = []  # List to store discriminator loss values\n",
        "\n",
        "# Define epochs to save generated images: initial, mid, and final\n",
        "save_epochs = [1, num_epochs // 2, num_epochs]  # Save generated images at the beginning, middle, and end of training\n",
        "\n",
        "# Loop through each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(dataloader):\n",
        "        # (a) Train the Discriminator\n",
        "        discriminator.zero_grad()  # Reset gradients for the discriminator\n",
        "        real_images = images.to(device)  # Move real images to the specified device\n",
        "        batch_size = real_images.size(0)  # Get the batch size\n",
        "\n",
        "        # 1. Generate fake images\n",
        "        z = torch.randn(batch_size, latent_dim, device=device)  # Sample random latent vectors\n",
        "        fake_images = generator(z)  # Generate fake images using the generator\n",
        "\n",
        "        # 2. Calculate discriminator output for real and fake images\n",
        "        real_output = discriminator(real_images).squeeze()  # Get discriminator output for real images\n",
        "        fake_output = discriminator(fake_images.detach()).squeeze()  # Get output for fake images (detach to avoid backpropagation through generator)\n",
        "\n",
        "        # 3. Compute discriminator loss and update\n",
        "        d_loss = discriminator_loss(real_output, fake_output)  # Compute discriminator loss\n",
        "        d_loss.backward()  # Backpropagate the loss\n",
        "        optimizer_D.step()  # Update the discriminator's parameters\n",
        "\n",
        "        # (b) Train the Generator\n",
        "        generator.zero_grad()  # Reset gradients for the generator\n",
        "        # Generate fake images again\n",
        "        z = torch.randn(batch_size, latent_dim, device=device)  # Sample random latent vectors\n",
        "        fake_images = generator(z)  # Generate new fake images\n",
        "\n",
        "        # Compute discriminator output for fake images\n",
        "        fake_output = discriminator(fake_images).squeeze()  # Get output for fake images\n",
        "\n",
        "        # Compute generator loss and update\n",
        "        g_loss = generator_loss(fake_output)  # Compute generator loss\n",
        "        g_loss.backward()  # Backpropagate the loss\n",
        "        optimizer_G.step()  # Update the generator's parameters\n",
        "\n",
        "        # Save loss values\n",
        "        g_losses.append(g_loss.item())  # Append generator loss to the list\n",
        "        d_losses.append(d_loss.item())  # Append discriminator loss to the list\n",
        "\n",
        "        # Print loss values every 200 steps\n",
        "        if (i + 1) % 200 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], \"\n",
        "                f\"Loss_G: {g_loss.item():.4f}, Loss_D: {d_loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "    # (c) Save a sample of generated images at initial, mid, and final stages\n",
        "    if (epoch + 1) in save_epochs:\n",
        "        with torch.no_grad():  # Disable gradient calculation for inference\n",
        "            z = torch.randn(10 * 10, latent_dim, device=device)  # Generate a grid of latent vectors\n",
        "            generated_images = generator(z).cpu()  # Generate images and move to CPU for visualization\n",
        "\n",
        "            # Visualize the generated images\n",
        "            fig, axs = plt.subplots(10, 10, figsize=(10, 10))  # Create a 10x10 grid of subplots\n",
        "            for i in range(10):\n",
        "                for j in range(10):\n",
        "                    img_idx = i * 10 + j  # Calculate index for the image\n",
        "                    axs[i, j].imshow(generated_images[img_idx].squeeze(), cmap='gray')  # Display the image\n",
        "                    axs[i, j].axis('off')  # Hide the axes\n",
        "\n",
        "            # Save the generated images to a file\n",
        "            plt.savefig(os.path.join('./', f\"generated_images_epoch_{epoch + 1}.png\"))\n",
        "            print(f\"Generated images saved for epoch {epoch + 1}\")\n",
        "            plt.close(fig)  # Close the figure to free up memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nEvfdb83esg",
        "outputId": "19595468-88a7-4142-e3ac-a1d01698d076"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [200/468], Loss_G: 8.3576, Loss_D: 0.0003\n",
            "Epoch [1/20], Step [400/468], Loss_G: 10.9884, Loss_D: 0.0000\n",
            "Generated images saved for epoch 1\n",
            "Epoch [2/20], Step [200/468], Loss_G: 12.1071, Loss_D: 0.0000\n",
            "Epoch [2/20], Step [400/468], Loss_G: 12.9566, Loss_D: 0.0000\n",
            "Epoch [3/20], Step [200/468], Loss_G: 13.6852, Loss_D: 0.0000\n",
            "Epoch [3/20], Step [400/468], Loss_G: 14.0746, Loss_D: 0.0000\n",
            "Epoch [4/20], Step [200/468], Loss_G: 14.5211, Loss_D: 0.0000\n",
            "Epoch [4/20], Step [400/468], Loss_G: 14.7669, Loss_D: 0.0000\n",
            "Epoch [5/20], Step [200/468], Loss_G: 15.0406, Loss_D: 0.0000\n",
            "Epoch [5/20], Step [400/468], Loss_G: 15.1874, Loss_D: 0.0000\n",
            "Epoch [6/20], Step [200/468], Loss_G: 15.4974, Loss_D: 0.0000\n",
            "Epoch [6/20], Step [400/468], Loss_G: 15.6457, Loss_D: 0.0000\n",
            "Epoch [7/20], Step [200/468], Loss_G: 15.8501, Loss_D: 0.0000\n",
            "Epoch [7/20], Step [400/468], Loss_G: 16.0476, Loss_D: 0.0000\n",
            "Epoch [8/20], Step [200/468], Loss_G: 16.1956, Loss_D: 0.0000\n",
            "Epoch [8/20], Step [400/468], Loss_G: 16.3829, Loss_D: 0.0000\n",
            "Epoch [9/20], Step [200/468], Loss_G: 16.5897, Loss_D: 0.0000\n",
            "Epoch [9/20], Step [400/468], Loss_G: 16.7476, Loss_D: 0.0000\n",
            "Epoch [10/20], Step [200/468], Loss_G: 16.8382, Loss_D: 0.0000\n",
            "Epoch [10/20], Step [400/468], Loss_G: 17.0063, Loss_D: 0.0000\n",
            "Generated images saved for epoch 10\n",
            "Epoch [11/20], Step [200/468], Loss_G: 17.1407, Loss_D: 0.0000\n",
            "Epoch [11/20], Step [400/468], Loss_G: 17.2996, Loss_D: 0.0000\n",
            "Epoch [12/20], Step [200/468], Loss_G: 17.4896, Loss_D: 0.0000\n",
            "Epoch [12/20], Step [400/468], Loss_G: 17.5960, Loss_D: -0.0000\n",
            "Epoch [13/20], Step [200/468], Loss_G: 17.6760, Loss_D: -0.0000\n",
            "Epoch [13/20], Step [400/468], Loss_G: 17.8290, Loss_D: -0.0000\n",
            "Epoch [14/20], Step [200/468], Loss_G: 18.0154, Loss_D: -0.0000\n",
            "Epoch [14/20], Step [400/468], Loss_G: 18.0994, Loss_D: -0.0000\n",
            "Epoch [15/20], Step [200/468], Loss_G: 18.2666, Loss_D: -0.0000\n",
            "Epoch [15/20], Step [400/468], Loss_G: 18.3438, Loss_D: -0.0000\n",
            "Epoch [16/20], Step [200/468], Loss_G: 18.4953, Loss_D: -0.0000\n",
            "Epoch [16/20], Step [400/468], Loss_G: 18.5814, Loss_D: -0.0000\n",
            "Epoch [17/20], Step [200/468], Loss_G: 18.7492, Loss_D: -0.0000\n",
            "Epoch [17/20], Step [400/468], Loss_G: 18.8379, Loss_D: -0.0000\n",
            "Epoch [18/20], Step [200/468], Loss_G: 19.0202, Loss_D: -0.0000\n",
            "Epoch [18/20], Step [400/468], Loss_G: 19.0746, Loss_D: -0.0000\n",
            "Epoch [19/20], Step [200/468], Loss_G: 19.2099, Loss_D: -0.0000\n",
            "Epoch [19/20], Step [400/468], Loss_G: 19.3467, Loss_D: -0.0000\n",
            "Epoch [20/20], Step [200/468], Loss_G: 19.5201, Loss_D: -0.0000\n",
            "Epoch [20/20], Step [400/468], Loss_G: 19.5580, Loss_D: -0.0000\n",
            "Generated images saved for epoch 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (d) Plotting the Loss\n",
        "plt.figure(figsize=(10, 5))  # Create a new figure with specified size\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")  # Set the title of the plot\n",
        "plt.plot(g_losses, label=\"G\")  # Plot generator loss with label \"G\"\n",
        "plt.plot(d_losses, label=\"D\")  # Plot discriminator loss with label \"D\"\n",
        "plt.xlabel(\"Iterations\")  # Label for the x-axis\n",
        "plt.ylabel(\"Loss\")  # Label for the y-axis\n",
        "plt.legend()  # Show legend to identify G and D\n",
        "\n",
        "# Save the loss plot to a file\n",
        "plt.savefig(os.path.join('./', \"loss_plot.png\"))\n",
        "print(\"Loss plot saved\")  # Print a confirmation message\n",
        "\n",
        "plt.show()  # Display the plot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "cMbDBeP15Xpb",
        "outputId": "313dbcb9-50ea-4df4-ee37-840a72e18aa3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss plot saved\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create real images directory\n",
        "os.makedirs(\"./real_images\", exist_ok=True)\n",
        "for i, (img, _) in enumerate(dataset):\n",
        "    if i >= 5000:\n",
        "        break\n",
        "    plt.imsave(f\"./real_images/{i}.png\", img.squeeze().numpy(), cmap='gray')\n",
        "\n",
        "\n",
        "fake_images = []\n",
        "for _ in range(100):  # 100 * batch_size = 12800 > 5000\n",
        "    z = torch.randn(batch_size,latent_dim,).to(device)\n",
        "    fake = generator(z).cpu().detach()\n",
        "    print(fake.shape)\n",
        "    fake_images.append(fake)\n",
        "fake_images = torch.cat(fake_images)[:5000]  # انتخاب 5000 نمونه\n",
        "\n",
        "# ذخیره در پوشه\n",
        "os.makedirs(\"./fake_images_gan\", exist_ok=True)\n",
        "for i, img in enumerate(fake_images):\n",
        "    plt.imsave(f\"./fake_images_gan/{i}.png\", img.squeeze(), cmap='gray')\n",
        "# Verify paths\n",
        "print(f\"Real images: {len(os.listdir('./real_images'))}\")\n",
        "print(f\"Fake images: {len(os.listdir('./fake_images_gan'))}\")\n",
        "\n",
        "# Calculate FID\n",
        "fid_value = fid_score.calculate_fid_given_paths(\n",
        "    [\"./real_images\", \"./fake_images_gan\"],\n",
        "    batch_size=50,\n",
        "    device=device,\n",
        "    dims=2048\n",
        ")\n",
        "print(f\"FID Score: {fid_value:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg1Z9evq5aKj",
        "outputId": "e59979b7-5413-4968-cb56-7543bc60f85a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "Real images: 5000\n",
            "Fake images: 5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:20<00:00,  4.93it/s]\n",
            "100%|██████████| 100/100 [00:20<00:00,  4.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID Score: 383.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"real_images.shape: {real_images.shape}\")\n",
        "print(f\"fake_images.shape: {fake_images.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH9yuYj2-sSy",
        "outputId": "cfedfd27-a163-4e28-b8f1-a67c463b9f91"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real_images.shape: torch.Size([128, 1, 28, 28])\n",
            "fake_images.shape: torch.Size([5000, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn  # Import the PyTorch neural network module\n",
        "\n",
        "### Cell 2: Define the architecture of the Critic (Discriminator)\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()  # Initialize the base class\n",
        "\n",
        "        # Define the model architecture as a sequential container\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),  # First conv layer: 1 input channel -> 32 output channels\n",
        "            nn.LeakyReLU(0.2),  # Leaky ReLU activation with negative slope 0.2\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),  # Second conv layer: 32 -> 64 channels\n",
        "            nn.LeakyReLU(0.2),  # Leaky ReLU activation\n",
        "\n",
        "            nn.Flatten(),  # Flatten the output from the conv layers for the fully connected layers\n",
        "\n",
        "            nn.Linear(64 * 7 * 7, 512),  # First fully connected layer: 64*7*7 inputs -> 512 outputs\n",
        "            nn.LeakyReLU(0.2),  # Leaky ReLU activation\n",
        "\n",
        "            nn.Linear(512, 1)  # Final layer outputs a single score (critic's score for the input)\n",
        "            # Note: No Sigmoid activation here, as WGAN uses raw scores for the Wasserstein distance\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)  # Pass the input through the defined architecture"
      ],
      "metadata": {
        "id": "I2PU-10Ku67P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to compute the gradient penalty\n",
        "def gradient_penalty(critic, real_images, fake_images, device):\n",
        "    batch_size = real_images.size(0)\n",
        "    alpha = torch.rand(batch_size, 1, 1, 1).to(device)  # Randomly sample alpha values\n",
        "\n",
        "    # Create interpolates between real and fake images\n",
        "    interpolates = (alpha * real_images + (1 - alpha) * fake_images).requires_grad_(True)\n",
        "\n",
        "    # Get the critic's output for the interpolated images\n",
        "    critic_interpolates = critic(interpolates)\n",
        "\n",
        "    # Compute gradients of the critic's output with respect to the interpolates\n",
        "    gradients = autograd.grad(\n",
        "        outputs=critic_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=torch.ones_like(critic_interpolates),  # Gradient of outputs w.r.t. the critic's output\n",
        "        create_graph=True,  # Allow gradients to be computed for higher order\n",
        "        retain_graph=True,  # Retain the graph for further backward passes\n",
        "    )[0]\n",
        "\n",
        "    # Reshape gradients to be of shape (batch_size, -1)\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "\n",
        "    # Compute the gradient penalty\n",
        "    penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()  # Penalty term for WGAN-GP\n",
        "    return penalty  # Return the computed gradient penalty\n",
        "# Function to compute the discriminator's loss\n",
        "def discriminator_loss(real_scores, fake_scores, gp, lambda_gp=10):\n",
        "    # WGAN-GP loss for the discriminator/critic\n",
        "    return -torch.mean(real_scores) + torch.mean(fake_scores) + lambda_gp * gp\n",
        "    # -mean(real_scores): Encourages the critic to output higher scores for real images\n",
        "    # mean(fake_scores): Encourages the critic to output lower scores for fake images\n",
        "    # lambda_gp * gp: Adds the gradient penalty to stabilize training\n",
        "\n",
        "# Function to compute the generator's loss\n",
        "def generator_loss(fake_scores):\n",
        "    # WGAN-GP loss for the generator\n",
        "    return -torch.mean(fake_scores)  # Encourages the generator to produce images that get high scores from the critic"
      ],
      "metadata": {
        "id": "MREFJvnyJTzV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_critic = 2  # کمتر کردن تعداد آموزش Critic\n",
        "lambda_gp = 10  # مقدار معمول\n",
        "d_losses = []\n",
        "g_losses = []\n",
        "generator = Generator(latent_dim).to(device)\n",
        "critic = Critic().to(device)\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
        "optimizer_D = optim.Adam(critic.parameters(), lr=0.0001, betas=(0.5, 0.9))"
      ],
      "metadata": {
        "id": "gACzV8bDseQW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_images, _) in enumerate(dataloader):\n",
        "        real_images = real_images.to(device)\n",
        "\n",
        "        # Train the Critic\n",
        "        for _ in range(n_critic):\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Generate fake images\n",
        "            z = torch.randn(real_images.size(0), latent_dim).to(device)\n",
        "            fake_images = generator(z)\n",
        "\n",
        "            # Compute the gradient penalty\n",
        "            gp = gradient_penalty(critic, real_images, fake_images, device)\n",
        "\n",
        "            # Compute the Critic's scores for real and fake images\n",
        "            real_scores = critic(real_images)\n",
        "            fake_scores = critic(fake_images)\n",
        "\n",
        "            # Compute the Critic loss\n",
        "            d_loss = discriminator_loss(real_scores, fake_scores, gp, lambda_gp)\n",
        "\n",
        "            # Backpropagate and optimize the Critic\n",
        "            d_loss.backward(retain_graph=True)\n",
        "            optimizer_D.step()\n",
        "\n",
        "            d_losses.append(d_loss.item())\n",
        "\n",
        "        # Train the Generator\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # z = torch.randn(real_images.size(0), latent_dim).to(device)\n",
        "        # fake_images = generator(z)\n",
        "        fake_scores = critic(fake_images)\n",
        "\n",
        "        # Compute the Generator loss\n",
        "        g_loss = generator_loss(fake_scores)\n",
        "\n",
        "        # Backpropagate and optimize the Generator\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        g_losses.append(g_loss.item())\n",
        "\n",
        "        if (i + 1) % 200 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], \"\n",
        "                f\"Loss_D: {d_loss.item():.4f}, Loss_G: {g_loss.item():.4f}\"\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgitsfJ-LJIj",
        "outputId": "b16bda21-74e3-490b-890d-c417a4aae55c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [200/468], Loss_D: -60.5416, Loss_G: -10.6923\n",
            "Epoch [1/20], Step [400/468], Loss_D: -53.3203, Loss_G: -14.7260\n",
            "Epoch [2/20], Step [200/468], Loss_D: -46.9187, Loss_G: -13.6150\n",
            "Epoch [2/20], Step [400/468], Loss_D: -45.2607, Loss_G: -12.7983\n",
            "Epoch [3/20], Step [200/468], Loss_D: -43.7685, Loss_G: -10.7753\n",
            "Epoch [3/20], Step [400/468], Loss_D: -43.0770, Loss_G: -10.6467\n",
            "Epoch [4/20], Step [200/468], Loss_D: -42.8592, Loss_G: -10.9415\n",
            "Epoch [4/20], Step [400/468], Loss_D: -42.9592, Loss_G: -12.5059\n",
            "Epoch [5/20], Step [200/468], Loss_D: -42.9256, Loss_G: -12.5267\n",
            "Epoch [5/20], Step [400/468], Loss_D: -42.5252, Loss_G: -12.7996\n",
            "Epoch [6/20], Step [200/468], Loss_D: -42.3657, Loss_G: -12.6100\n",
            "Epoch [6/20], Step [400/468], Loss_D: -42.2631, Loss_G: -12.0380\n",
            "Epoch [7/20], Step [200/468], Loss_D: -42.2875, Loss_G: -12.6775\n",
            "Epoch [7/20], Step [400/468], Loss_D: -42.7263, Loss_G: -13.4139\n",
            "Epoch [8/20], Step [200/468], Loss_D: -42.7943, Loss_G: -14.5782\n",
            "Epoch [8/20], Step [400/468], Loss_D: -42.7048, Loss_G: -13.9990\n",
            "Epoch [9/20], Step [200/468], Loss_D: -42.7948, Loss_G: -14.4946\n",
            "Epoch [9/20], Step [400/468], Loss_D: -42.5562, Loss_G: -14.3652\n",
            "Epoch [10/20], Step [200/468], Loss_D: -42.6791, Loss_G: -13.5497\n",
            "Epoch [10/20], Step [400/468], Loss_D: -42.8122, Loss_G: -13.0434\n",
            "Epoch [11/20], Step [200/468], Loss_D: -42.5441, Loss_G: -12.6314\n",
            "Epoch [11/20], Step [400/468], Loss_D: -42.3189, Loss_G: -12.5186\n",
            "Epoch [12/20], Step [200/468], Loss_D: -42.4654, Loss_G: -12.0584\n",
            "Epoch [12/20], Step [400/468], Loss_D: -42.4505, Loss_G: -12.1097\n",
            "Epoch [13/20], Step [200/468], Loss_D: -42.3261, Loss_G: -12.1693\n",
            "Epoch [13/20], Step [400/468], Loss_D: -42.5704, Loss_G: -13.2565\n",
            "Epoch [14/20], Step [200/468], Loss_D: -42.5810, Loss_G: -12.9281\n",
            "Epoch [14/20], Step [400/468], Loss_D: -42.4167, Loss_G: -12.5840\n",
            "Epoch [15/20], Step [200/468], Loss_D: -42.2852, Loss_G: -12.8481\n",
            "Epoch [15/20], Step [400/468], Loss_D: -42.1493, Loss_G: -12.5124\n",
            "Epoch [16/20], Step [200/468], Loss_D: -42.4655, Loss_G: -11.6231\n",
            "Epoch [16/20], Step [400/468], Loss_D: -42.2099, Loss_G: -12.4178\n",
            "Epoch [17/20], Step [200/468], Loss_D: -42.3466, Loss_G: -11.4769\n",
            "Epoch [17/20], Step [400/468], Loss_D: -42.2624, Loss_G: -11.3718\n",
            "Epoch [18/20], Step [200/468], Loss_D: -42.3002, Loss_G: -9.1798\n",
            "Epoch [18/20], Step [400/468], Loss_D: -42.2440, Loss_G: -9.3172\n",
            "Epoch [19/20], Step [200/468], Loss_D: -42.1739, Loss_G: -9.7454\n",
            "Epoch [19/20], Step [400/468], Loss_D: -42.2498, Loss_G: -10.0376\n",
            "Epoch [20/20], Step [200/468], Loss_D: -42.0299, Loss_G: -9.6722\n",
            "Epoch [20/20], Step [400/468], Loss_D: -42.2061, Loss_G: -9.7549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  # Import matplotlib for plotting\n",
        "\n",
        "# Plotting the losses\n",
        "plt.plot(d_losses, label='D Loss')  # Plot the Discriminator loss\n",
        "plt.plot(g_losses, label='G Loss')  # Plot the Generator loss\n",
        "plt.xlabel('Iterations')  # Label for the x-axis\n",
        "plt.ylabel('Loss')  # Label for the y-axis\n",
        "plt.legend()  # Show legend to differentiate between D and G losses\n",
        "plt.title('Losses during Training')  # Set the title of the plot\n",
        "plt.show()  # Display the plot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ooi2JCP0Ltc-",
        "outputId": "332284b0-4fd7-4026-c8c9-ee6e26072653"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create real images directory\n",
        "os.makedirs(\"./real_images\", exist_ok=True)\n",
        "for i, (img, _) in enumerate(dataset):\n",
        "    if i >= 5000:\n",
        "        break\n",
        "    plt.imsave(f\"./real_images/{i}.png\", img.squeeze().numpy(), cmap='gray')\n",
        "\n",
        "\n",
        "fake_images = []\n",
        "for _ in range(100):  # 100 * batch_size = 12800 > 5000\n",
        "    z = torch.randn(batch_size, latent_dim).to(device)\n",
        "    fake = generator(z).cpu().detach()\n",
        "    print(fake.shape)\n",
        "    fake_images.append(fake)\n",
        "fake_images = torch.cat(fake_images)[:5000]  # انتخاب 5000 نمونه\n",
        "\n",
        "# ذخیره در پوشه\n",
        "os.makedirs(\"./fake_images\", exist_ok=True)\n",
        "for i, img in enumerate(fake_images):\n",
        "    plt.imsave(f\"./fake_images_wgan/{i}.png\", img.squeeze(), cmap='gray')\n",
        "# Verify paths\n",
        "print(f\"Real images: {len(os.listdir('./real_images'))}\")\n",
        "print(f\"Fake images: {len(os.listdir('./fake_images_wgan'))}\")\n",
        "\n",
        "# Calculate FID\n",
        "fid_value = fid_score.calculate_fid_given_paths(\n",
        "    [\"./real_images\", \"./fake_images_wgan\"],\n",
        "    batch_size=50,\n",
        "    device=device,\n",
        "    dims=2048\n",
        ")\n",
        "print(f\"FID Score: {fid_value:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bb1QyZ7tEnI",
        "outputId": "c54bf331-8948-4daf-eda0-912b2eafc810"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "Real images: 5000\n",
            "Fake images: 5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100%|██████████| 91.2M/91.2M [00:00<00:00, 114MB/s]\n",
            "100%|██████████| 100/100 [00:19<00:00,  5.09it/s]\n",
            "100%|██████████| 100/100 [00:19<00:00,  5.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID Score: 87.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### Cell 4: Define Residual Block for Generator\n",
        "class ResidualBlockG(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, upsample=True):\n",
        "        super().__init__()\n",
        "        self.upsample = upsample  # Flag to determine whether to upsample\n",
        "\n",
        "        # Define the main block of the residual block\n",
        "        self.block = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),  # Batch normalization\n",
        "            nn.ReLU(),  # ReLU activation\n",
        "            nn.Upsample(scale_factor=2, mode='nearest') if upsample else nn.Identity(),  # Upsampling if needed\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),  # First convolution\n",
        "            nn.BatchNorm2d(out_channels),  # Batch normalization\n",
        "            nn.ReLU(),  # ReLU activation\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # Second convolution\n",
        "        )\n",
        "\n",
        "        # Define the shortcut connection\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode='nearest') if upsample else nn.Identity(),  # Upsampling if needed\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1)  # 1x1 convolution for matching dimensions\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Return the sum of the main block output and the shortcut connection\n",
        "        return self.block(x) + self.shortcut(x)\n",
        "\n",
        "\n",
        "### Cell 5: Implement Generator with Architecture from Table 4\n",
        "class SSGenerator(nn.Module):\n",
        "    def __init__(self, latent_dim=128):\n",
        "        super().__init__()\n",
        "        # Initial layer to project the latent vector\n",
        "        self.init_layer = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256 * 4 * 4),  # Fully connected layer to expand latent vector\n",
        "            nn.BatchNorm1d(256 * 4 * 4),  # Batch normalization\n",
        "            nn.ReLU()  # ReLU activation\n",
        "        )\n",
        "\n",
        "        # Residual blocks to upscale and refine the generated images\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            ResidualBlockG(256, 256, upsample=True),  # First residual block\n",
        "            ResidualBlockG(256, 256, upsample=True),  # Second residual block\n",
        "            ResidualBlockG(256, 256, upsample=True)   # Third residual block\n",
        "        )\n",
        "\n",
        "        # Final layers to produce the output image\n",
        "        self.final_layers = nn.Sequential(\n",
        "            nn.BatchNorm2d(256),  # Batch normalization\n",
        "            nn.ReLU(),  # ReLU activation\n",
        "            nn.Conv2d(256, 1, kernel_size=3, padding=1),  # Final convolution to reduce channels to 1 (grayscale image)\n",
        "            nn.Tanh()  # Tanh activation to output values in the range [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        # Forward pass through the generator\n",
        "        x = self.init_layer(z)  # Pass latent vector through initial layer\n",
        "        x = x.view(-1, 256, 4, 4)  # Reshape to (batch_size, channels, height, width)\n",
        "        x = self.res_blocks(x)  # Pass through residual blocks\n",
        "        return self.final_layers(x)  # Pass through final layers to get output image"
      ],
      "metadata": {
        "id": "883K7pkeOwXD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Residual Block برای Discriminator مطابق جدول 7\n",
        "class ResidualBlockD(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample=True):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample  # Flag to determine if downsampling is needed\n",
        "\n",
        "        # Block1\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.ReLU() if in_channels != 1 else nn.Identity(),  # ReLU (not for the first block)\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),  # Conv2D 3x3\n",
        "            nn.utils.spectral_norm(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)),  # Spectral Norm\n",
        "            nn.ReLU(),  # ReLU\n",
        "        )\n",
        "\n",
        "        # Block2\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),  # Conv2D 3x3\n",
        "            nn.utils.spectral_norm(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)),  # Spectral Norm\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),  # AvgPool2D 2x2\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),  # AvgPool2D 2x2\n",
        "        )\n",
        "\n",
        "        # Shortcut connection\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),  # AvgPool2D 2x2\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),  # AvgPool2D 2x2\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0),  # Conv2D 1x1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block1\n",
        "        out1 = self.block1(x)\n",
        "\n",
        "        # Block2\n",
        "        out2 = self.block2(out1)\n",
        "\n",
        "        # Shortcut connection\n",
        "        shortcut = self.shortcut(x)\n",
        "\n",
        "        # Combine Block1 + Block2 with shortcut\n",
        "        return out2 + shortcut\n",
        "\n",
        "# Discriminator برای SSGAN\n",
        "class SSDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Residual blocks to downsample and refine the input images\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            ResidualBlockD(1, 128, downsample=True),  # First residual block (downsample)\n",
        "            ResidualBlockD(128, 128, downsample=True),  # Second residual block (downsample)\n",
        "            ResidualBlockD(128, 128, downsample=False),  # Third residual block (no downsample)\n",
        "            ResidualBlockD(128, 128, downsample=False),  # Fourth residual block (no downsample)\n",
        "        )\n",
        "\n",
        "        # Final layers to produce the output\n",
        "        self.final_layers = nn.Sequential(\n",
        "            nn.Linear(128 * 7 * 7, 1),  # Fully connected layer to output a single value (real/fake)\n",
        "            nn.Linear(128 * 7 * 7, 4),  # Fully connected layer for self-supervised task (e.g., rotation prediction)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the discriminator\n",
        "        x = self.res_blocks(x)  # Pass through residual blocks\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        real_fake_output = self.final_layers[0](x)  # Output for real/fake classification\n",
        "        self_supervised_output = self.final_layers[1](x)  # Output for self-supervised task\n",
        "        return real_fake_output, self_supervised_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6WdJjqol0YJY",
        "outputId": "e57c73e0-c575-4a00-9f4d-4a7beb2dd273"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0fe4060aa84e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Residual Block برای Discriminator مطابق جدول 7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mResidualBlockD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = SSGenerator(latent_dim=128).to(device)\n",
        "discriminator = SSDiscriminator().to(device)\n",
        "\n",
        "# تعریف بهینه‌سازها\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# تعریف توابع خطا\n",
        "criterion = nn.BCEWithLogitsLoss()  # برای تشخیص واقعی/جعلی\n",
        "criterion_ss = nn.CrossEntropyLoss()  # برای وظیفه خودنظارتی (مثلاً پیش‌بینی چرخش)\n",
        "\n",
        "# آموزش مدل\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (real_images, _) in enumerate(dataloader):\n",
        "        real_images = real_images.to(device)\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # (a) Train Discriminator\n",
        "        discriminator.zero_grad()\n",
        "\n",
        "        # 1. Train with real images\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # Discriminator output for real images\n",
        "        real_output, real_ss_output = discriminator(real_images)\n",
        "        d_loss_real = criterion(real_output, real_labels)\n",
        "\n",
        "        # 2. Train with fake images\n",
        "        z = torch.randn(batch_size, 128).to(device)  # Sample random latent vectors\n",
        "        fake_images = generator(z)\n",
        "        fake_output, fake_ss_output = discriminator(fake_images.detach())\n",
        "        d_loss_fake = criterion(fake_output, fake_labels)\n",
        "\n",
        "        # 3. Self-supervised task (e.g., rotation prediction)\n",
        "        # Assuming rotation prediction with 4 classes (0°, 90°, 180°, 270°)\n",
        "        rotation_labels = torch.randint(0, 4, (batch_size,)).to(device)\n",
        "        d_loss_ss = criterion_ss(real_ss_output, rotation_labels)\n",
        "\n",
        "        # Total discriminator loss\n",
        "        d_loss = d_loss_real + d_loss_fake + d_loss_ss\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # (b) Train Generator\n",
        "        generator.zero_grad()\n",
        "\n",
        "        # Generate fake images again\n",
        "        z = torch.randn(batch_size, 128).to(device)\n",
        "        fake_images = generator(z)\n",
        "        fake_output, _ = discriminator(fake_images)\n",
        "\n",
        "        # Generator loss\n",
        "        g_loss = criterion(fake_output, real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Print losses every 100 steps\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], \"\n",
        "                  f\"Loss_D: {d_loss.item():.4f}, Loss_G: {g_loss.item():.4f}\")\n",
        "\n",
        "    # Save generated images at the end of each epoch\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(100, 128).to(device)  # Generate 100 random latent vectors\n",
        "            generated_images = generator(z).cpu()  # Generate images and move to CPU\n",
        "\n",
        "            # Save generated images\n",
        "            fig, axs = plt.subplots(10, 10, figsize=(10, 10))\n",
        "            for i in range(10):\n",
        "                for j in range(10):\n",
        "                    img_idx = i * 10 + j\n",
        "                    axs[i, j].imshow(generated_images[img_idx].squeeze(), cmap='gray')\n",
        "                    axs[i, j].axis('off')\n",
        "            plt.savefig(f\"generated_images_epoch_{epoch + 1}.png\")\n",
        "            plt.close(fig)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "eZihZnZH4iGp",
        "outputId": "0ee26075-0477-459a-bb2f-00b53c2c737e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [128, 128, 1, 1], expected input[128, 1, 8, 8] to have 128 channels, but got 1 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-5ca2e844385b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Discriminator output for real images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mreal_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_ss_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-f68b1452b55d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Forward pass through the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pass through residual blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Flatten the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mreal_fake_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Output for real/fake classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-f68b1452b55d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Shortcut connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Combine Block1 + Block2 with shortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 128, 1, 1], expected input[128, 1, 8, 8] to have 128 channels, but got 1 channels instead"
          ]
        }
      ]
    }
  ]
}