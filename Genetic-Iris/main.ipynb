{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27039b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دقت شبکه عصبی استاندارد: 0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pydevcasts/Templates/MLHub/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# بارگذاری دیتاست Iris\n",
    "data = load_iris()\n",
    "X = data.data        # ویژگی‌ها\n",
    "y = data.target      # برچسب‌ها (0, 1, 2)\n",
    "\n",
    "# تقسیم داده به آموزش و تست\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# تعریف و آموزش شبکه عصبی MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,),\n",
    "                    activation='relu',\n",
    "                    solver='adam',\n",
    "                    max_iter=300,\n",
    "                    random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# پیش‌بینی روی داده‌های تست و محاسبه دقت\n",
    "y_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"دقت شبکه عصبی استاندارد:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pygad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c8e6b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بهترین میزان تناسب (دقت) به دست آمده در آموزش: 0.9833333333333333\n",
      "دقت روی مجموعه تست با وزن‌های بهینه شده توسط GA: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygad\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# تعریف توابع فعالسازی\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    # پیاده‌سازی softmax به صورت عددی پایدار\n",
    "    exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "# تابع پیش‌انتشار شبکه عصبی (دو لایه: یک لایه پنهان و خروجی)\n",
    "def forward_propagation(X, solution):\n",
    "    # تعیین ابعاد (ورودی، پنهان، خروجی)\n",
    "    input_dim = 4    # ۴ ویژگی دیتاست Iris\n",
    "    hidden_dim = 10  # تعداد نورون‌های لایه پنهان\n",
    "    output_dim = 3   # تعداد کلاس‌ها (خروجی)\n",
    "    \n",
    "    # استخراج وزن‌ها و بایاس‌ها از بردار حل (solution)\n",
    "    # وزن‌های ورودی به پنهان: از اندیس 0 تا 4*10\n",
    "    W1 = solution[0: input_dim * hidden_dim].reshape((input_dim, hidden_dim))\n",
    "    # بایاس لایه پنهان: اندیس بعدی به اندازه hidden_dim\n",
    "    b1 = solution[input_dim * hidden_dim: input_dim * hidden_dim + hidden_dim].reshape((hidden_dim,))\n",
    "    # وزن‌های لایه پنهان به خروجی: بعد از بایاس پنهان، به اندازه hidden_dim*output_dim\n",
    "    W2 = solution[input_dim * hidden_dim + hidden_dim: input_dim * hidden_dim + hidden_dim + hidden_dim * output_dim].reshape((hidden_dim, output_dim))\n",
    "    # بایاس خروجی: باقی‌مانده\n",
    "    b2 = solution[input_dim * hidden_dim + hidden_dim + hidden_dim * output_dim:].reshape((output_dim,))\n",
    "    \n",
    "    # محاسبه خروجی لایه پنهان\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    \n",
    "    # محاسبه خروجی نهایی با استفاده از softmax\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    output = softmax(Z2)\n",
    "    return output\n",
    "\n",
    "# بارگذاری دیتاست Iris و تقسیم به آموزش و تست\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# اصلاح تابع تناسب (Fitness Function)\n",
    "def fitness_func(ga_instance, solution, solution_idx):\n",
    "    predictions_prob = forward_propagation(X_train, solution)\n",
    "    predictions = np.argmax(predictions_prob, axis=1)\n",
    "    accuracy = np.mean(predictions == y_train)\n",
    "    return accuracy  # دقت بالاتر بهتر است.\n",
    "\n",
    "# تعیین تعداد ژن‌ها (کل تعداد پارامترها در شبکه)\n",
    "input_dim = 4\n",
    "hidden_dim = 10\n",
    "output_dim = 3\n",
    "num_genes = input_dim * hidden_dim + hidden_dim + hidden_dim * output_dim + output_dim  # 4*10 + 10 + 10*3 + 3 = 83\n",
    "\n",
    "# تنظیمات الگوریتم ژنتیک\n",
    "ga_instance = pygad.GA(num_generations=50,\n",
    "                       num_parents_mating=10,\n",
    "                       fitness_func=fitness_func,\n",
    "                       sol_per_pop=20,\n",
    "                       num_genes=num_genes,\n",
    "                       mutation_percent_genes=10,\n",
    "                       mutation_type=\"random\",\n",
    "                       random_mutation_min_val=-1,\n",
    "                       random_mutation_max_val=1)\n",
    "\n",
    "# اجرای الگوریتم ژنتیک\n",
    "ga_instance.run()\n",
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"بهترین میزان تناسب (دقت) به دست آمده در آموزش:\", solution_fitness)\n",
    "\n",
    "# ارزیابی شبکه با وزن‌های بهینه شده روی داده‌های تست\n",
    "predictions_prob_test = forward_propagation(X_test, solution)\n",
    "predictions_test = np.argmax(predictions_prob_test, axis=1)\n",
    "accuracy_test = np.mean(predictions_test == y_test)\n",
    "print(\"دقت روی مجموعه تست با وزن‌های بهینه شده توسط GA:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1d22fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%` not found.\n"
     ]
    }
   ],
   "source": [
    "%% Optimizing MLP Using Genetic Algorithm in Octave\n",
    "\n",
    "% 1. Load Iris dataset\n",
    "filename = 'upload/iris.csv'; % Ensure iris.csv is in your working directory\n",
    "fileID = fopen(filename, 'r');\n",
    "if fileID == -1\n",
    "    error('Error loading the dataset. Ensure the file \"%s\" exists.', filename);\n",
    "end\n",
    "\n",
    "data = textscan(fileID, '%f %f %f %f %s', 'Delimiter', ',', 'HeaderLines', 0);\n",
    "fclose(fileID);\n",
    "\n",
    "inputs = [data{1}, data{2}, data{3}, data{4}]'; % Features\n",
    "species = data{5};                              % Labels\n",
    "\n",
    "% Convert labels to one-hot format\n",
    "unique_species = unique(species);\n",
    "num_samples = numel(species);\n",
    "targets = zeros(numel(unique_species), num_samples);\n",
    "for i = 1:num_samples\n",
    "    idx = find(strcmp(unique_species, species{i}));\n",
    "    targets(idx, i) = 1;\n",
    "end\n",
    "\n",
    "% 2. Define MLP structure\n",
    "input_dim = size(inputs, 1);\n",
    "hidden_dim = 10;\n",
    "output_dim = size(targets, 1);\n",
    "\n",
    "% Forward propagation function\n",
    "function [output, hidden] = forward(X, W1, b1, W2, b2)\n",
    "    hidden = max(0, W1 * X + b1); % ReLU activation\n",
    "    output = softmax(W2 * hidden + b2);\n",
    "end\n",
    "\n",
    "% Softmax function\n",
    "function output = softmax(x)\n",
    "    exp_x = exp(x - max(x, [], 1)); % Stability improvement\n",
    "    output = exp_x ./ sum(exp_x, 1);\n",
    "end\n",
    "\n",
    "% Cost function\n",
    "function fitness = mlp_cost(solution, inputs, targets)\n",
    "    input_dim = size(inputs, 1);\n",
    "    hidden_dim = 10;\n",
    "    output_dim = size(targets, 1);\n",
    "\n",
    "    W1 = reshape(solution(1:hidden_dim*input_dim), hidden_dim, input_dim);\n",
    "    b1 = reshape(solution(hidden_dim*input_dim+1:hidden_dim*input_dim+hidden_dim), hidden_dim, 1);\n",
    "    W2 = reshape(solution(hidden_dim*input_dim+hidden_dim+1:hidden_dim*input_dim+hidden_dim+hidden_dim*output_dim), output_dim, hidden_dim);\n",
    "    b2 = reshape(solution(hidden_dim*input_dim+hidden_dim+hidden_dim*output_dim+1:end), output_dim, 1);\n",
    "\n",
    "    [outputs, ~] = forward(inputs, W1, b1, W2, b2);\n",
    "\n",
    "    [~, predicted_labels] = max(outputs, [], 1);\n",
    "    [~, true_labels] = max(targets, [], 1);\n",
    "    accuracy = sum(predicted_labels == true_labels) / numel(true_labels);\n",
    "\n",
    "    % Handle invalid accuracy cases\n",
    "    if isnan(accuracy) || isinf(accuracy)\n",
    "        fitness = Inf; % Penalize invalid solutions\n",
    "    else\n",
    "        fitness = -accuracy; % GA minimizes the cost\n",
    "    end\n",
    "end\n",
    "\n",
    "% 3. Genetic Algorithm implementation\n",
    "num_genes = hidden_dim * input_dim + hidden_dim + hidden_dim * output_dim + output_dim;\n",
    "population_size = 50;\n",
    "num_generations = 50;\n",
    "mutation_rate = 0.01;\n",
    "\n",
    "population = rand(population_size, num_genes) * 2 - 1; % Initialize population\n",
    "overall_best_fitness = Inf;\n",
    "optimal_solution = [];\n",
    "\n",
    "for generation = 1:num_generations\n",
    "    fitness_scores = zeros(population_size, 1);\n",
    "    for i = 1:population_size\n",
    "        fitness_scores(i) = mlp_cost(population(i, :), inputs, targets);\n",
    "    end\n",
    "\n",
    "    % Avoid invalid fitness values\n",
    "    valid_indices = ~isinf(fitness_scores);\n",
    "    if ~any(valid_indices)\n",
    "        fprintf('All solutions invalid at generation %d. Exiting.\\n', generation);\n",
    "        break;\n",
    "    end\n",
    "\n",
    "    % Select parents (tournament selection)\n",
    "    tournament_size = 3;\n",
    "    parents = zeros(population_size, num_genes);\n",
    "    for i = 1:population_size\n",
    "        tournament_indices = randi(population_size, 1, tournament_size);\n",
    "        [~, winner] = min(fitness_scores(tournament_indices));\n",
    "        parents(i, :) = population(tournament_indices(winner), :);\n",
    "    end\n",
    "\n",
    "    % Crossover (uniform crossover)\n",
    "    offspring = zeros(population_size, num_genes);\n",
    "    for i = 1:2:population_size\n",
    "        mask = randi([0, 1], 1, num_genes);\n",
    "        offspring(i, :) = parents(i, :) .* mask + parents(i+1, :) .* (1 - mask);\n",
    "        offspring(i+1, :) = parents(i+1, :) .* mask + parents(i, :) .* (1 - mask);\n",
    "    end\n",
    "\n",
    "    % Mutation\n",
    "    mutation_mask = rand(population_size, num_genes) < mutation_rate;\n",
    "    offspring(mutation_mask) = offspring(mutation_mask) + randn(sum(mutation_mask(:)), 1) * 0.1;\n",
    "\n",
    "    population = offspring;\n",
    "\n",
    "    % Track best solution\n",
    "    [best_fitness, best_idx] = min(fitness_scores(valid_indices));\n",
    "    if best_fitness < overall_best_fitness\n",
    "        overall_best_fitness = best_fitness;\n",
    "        optimal_solution = population(valid_indices(best_idx), :);\n",
    "    end\n",
    "\n",
    "    fprintf('Generation %d, Best Fitness: %.4f\\n', generation, -overall_best_fitness);\n",
    "end\n",
    "\n",
    "% Handle cases where no valid solution was found\n",
    "if isempty(optimal_solution)\n",
    "    error('No valid solution found. Check data or algorithm settings.');\n",
    "end\n",
    "\n",
    "% Extract optimized weights and biases\n",
    "W1_opt = reshape(optimal_solution(1:hidden_dim*input_dim), hidden_dim, input_dim);\n",
    "b1_opt = reshape(optimal_solution(hidden_dim*input_dim+1:hidden_dim*input_dim+hidden_dim), hidden_dim, 1);\n",
    "W2_opt = reshape(optimal_solution(hidden_dim*input_dim+hidden_dim+1:hidden_dim*input_dim+hidden_dim+hidden_dim*output_dim), output_dim, hidden_dim);\n",
    "b2_opt = reshape(optimal_solution(hidden_dim*input_dim+hidden_dim+hidden_dim*output_dim+1:end), output_dim, 1);\n",
    "\n",
    "% Evaluate optimized network\n",
    "[outputs_opt, ~] = forward(inputs, W1_opt, b1_opt, W2_opt, b2_opt);\n",
    "[~, predicted_labels_opt] = max(outputs_opt, [], 1);\n",
    "[~, true_labels_opt] = max(targets, [], 1);\n",
    "accuracy_opt = sum(predicted_labels_opt == true_labels_opt) / numel(true_labels_opt);\n",
    "fprintf('Final Optimized Accuracy: %.2f%%\\n', accuracy_opt * 100);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
