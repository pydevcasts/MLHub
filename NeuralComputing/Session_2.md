### **بخش اول: تشریحی**

**سؤال 1: نقش لایه پنهان در یک شبکه عصبی چیست؟**  
**پاسخ:**

لایه پنهان باعث ایجاد توانایی برای یادگیری روابط **غیرخطی** بین ورودی‌ها و خروجی‌ها در شبکه می‌شود. این لایه اطلاعات را از ورودی گرفته و از طریق وزن‌ها و تابع فعال‌سازی، ویژگی‌های مهم را استخراج می‌کند. ⚙️🔍➡️📊

---

**سؤال 2: تفاوت بین توابع فعال‌سازی سیگموئید و تانژانت هیپربولیک چیست؟**  
**پاسخ:**

تابع **سیگموئید** خروجی را بین 0 تا 1 نگه می‌دارد، در حالی که تابع **تانژانت هیپربولیک (tanh)** خروجی را بین -1 و 1 دارد. این تفاوت باعث می‌شود که tanh در بسیاری از موارد سریع‌تر به تعادل برسد. 0️⃣↔️1️⃣ و ➖1️⃣↔️➕1️⃣

---

**سؤال 3: الگوریتم گرادیان نزولی چگونه عمل می‌کند؟**  
**پاسخ:**

این الگوریتم برای کاهش مقدار خطا در شبکه عصبی، با حرکت در جهت **منفی گرادیان تابع خطا**، وزن‌ها را به گونه‌ای تنظیم می‌کند که خطا کاهش یابد. ⬇️📉🔧

---

**سؤال 4: مراحل آموزش یک شبکه عصبی را نام ببرید.**  
**پاسخ:** 

1. **آموزش (Training):** یادگیری الگوهای داده‌های ورودی ✍️  
2. **تعمیم (Generalization):** توانایی پاسخ به ورودی‌های جدید 🧠  
3. **اجرا (Execution):** استفاده از شبکه برای پیش‌بینی یا طبقه‌بندی 🔮

---

**سؤال 5: شرط پایان الگوریتم BP چیست؟**  
**پاسخ:** 

* رسیدن به تعداد مشخصی از تکرار ⏳  
* کاهش خطا به کمتر از یک مقدار معین ✅  
* افزایش خطا در داده‌های اعتبارسنجی (برای جلوگیری از overfitting) ❌

---

**سؤال 6: مشکلات روش Gradient Descent را نام ببرید.**  
**پاسخ:**

* ممکن است زمان زیادی برای همگرایی لازم باشد 🐌  
* امکان گیر افتادن در مینیمم محلی وجود دارد ⚠️

---

**سؤال 7: چرا مشکل Overfitting در شبکه‌های عصبی رخ می‌دهد؟ چگونه می‌توان از آن جلوگیری کرد؟**  
**پاسخ:**

وقتی شبکه بیش از حد روی داده‌های آموزشی تمرین می‌کند 🧠📚، ممکن است ویژگی‌های خاص و حتی نویز موجود در آن داده‌ها را یاد بگیرد، اما نتواند برای داده‌های جدید عملکرد خوبی داشته باشد ❗. برای جلوگیری از Overfitting می‌توان از روش‌هایی مثل **اعتبارسنجی** (validation) ✅، **Dropout** ❎، یا **توقف زودهنگام** ⏹️ استفاده کرد.

---

**سؤال 8: در یک نرون مصنوعی، چه نقشی برای سیناپس‌ها در نظر گرفته شده است؟**  
**پاسخ:**

سیناپس‌ها مانند پل ارتباطی بین نرون‌ها عمل می‌کنند 🔗. هر سیناپس دارای یک وزن است ⚖️ که نشان‌دهنده شدت ارتباط بین نرون‌هاست. این وزن‌ها در حین آموزش تنظیم می‌شوند تا شبکه بتواند به پاسخ صحیح برسد ✅.

---

**سؤال 9: ساختار یک نرون مصنوعی از چه اجزایی تشکیل شده است؟**  
**پاسخ:**

یک نرون مصنوعی شبیه‌سازی ساده‌ای از نرون زیستی 🧠 است که از سه بخش اصلی تشکیل شده:  
1. **دندریت‌ها (Dendrites):** دریافت‌کننده‌ی سیگنال‌های ورودی 📥  
2. **بدنه سلول (Soma):** پردازشگر اطلاعات و محاسبه‌کننده‌ی مجموع وزن‌دار سیگنال‌ها ⚙️  
3. **آکسون (Axon):** انتقال‌دهنده سیگنال خروجی به نرون‌های دیگر 📤  

---

**سؤال 10: شبکه‌های چندلایه (MLP) چگونه کار می‌کنند؟**  
**پاسخ:**

در شبکه‌های چندلایه یا **MLP (Multi-Layer Perceptron)**، اطلاعات به صورت مرحله‌ای بین لایه‌ها منتقل می‌شوند 🔄. لایه‌ها شامل:  
* **لایه ورودی:** دریافت‌کننده داده‌ها 🎯  
* **لایه پنهان (Hidden layer):** استخراج‌کننده ویژگی‌های پیچیده 🌐  
* **لایه خروجی:** تولیدکننده پاسخ نهایی 📊  

---

**سؤال 11: چه تفاوتی بین توابع فعال‌سازی Sigmoid و ReLU وجود دارد؟**  
**پاسخ:**

تابع **Sigmoid** خروجی را بین 0 تا 1 نگه می‌دارد و مناسب برای مدل‌هایی با احتمال یا دسته‌بندی دوگانه است 🎯. اما ممکن است در شبکه‌های عمیق باعث مشکل **vanishing gradient** شود 😵. در مقابل، تابع **ReLU**، خروجی را به صورت مستقیم و غیرمنفی بازمی‌گرداند و ساده‌تر و سریع‌تر است ⚡.

---

**سؤال 12: چرا وجود لایه‌های پنهان برای حل مسائل پیچیده مثل XOR ضروری است؟**  
**پاسخ:**

چون XOR یک مسئله **غیر خطی** است و شبکه‌های تک‌لایه نمی‌توانند آن را یاد بگیرند. لایه پنهان باعث افزایش قدرت تفکیک‌پذیری شبکه می‌شود. ❌➕❌ = ✅

---


**سؤال 13: چرا استفاده از تابع فعال‌سازی ReLU در شبکه‌های عصبی محبوب است؟**  
**پاسخ:**

تابع ReLU با فرمول $f(x) = \max(0, x)$ تعریف می‌شود. این تابع بسیار ساده، سریع، و موثر است ⚡. مزیت اصلی آن نسبت به توابعی مثل سیگموئید یا تانژانت هیپربولیک این است که باعث **انتشار بهتر گرادیان** در شبکه می‌شود و مشکل **vanishing gradient** را کاهش می‌دهد. در واقع، با ReLU، نرون‌هایی که ورودی مثبت دارند فعال می‌شوند (روشن می‌شن) 💡 و نرون‌هایی که ورودی منفی دارند خاموش می‌مونن ❌.



---


**سؤال 14: چرا تابع فعال‌سازی غیرخطی در شبکه‌های عصبی ضروری است؟**
**پاسخ:**

اگر از توابع خطی مثل $f(x) = ax + b$ استفاده کنیم، حتی در صورت اضافه کردن چندین لایه، شبکه همچنان عملکرد یک تابع خطی رو خواهد داشت ➕➕➕.
اما توابع **غیرخطی** مثل Sigmoid یا Tanh به شبکه اجازه می‌دن تا تصمیم‌های پیچیده‌تری بگیره 🧠✨.
این توابع، مرز تصمیم‌گیری (decision boundary) شبکه رو **منعطف** می‌کنن، که برای دسته‌بندی داده‌های واقعی ضروریه 🎯.

---

**سؤال 15: تفاوت بین داده‌های آموزشی و داده‌های اعتبارسنجی چیست؟**
**پاسخ:**

📦 داده‌های آموزشی (**Training set**) برای آموزش وزن‌های شبکه استفاده می‌شن، یعنی شبکه از اون‌ها یاد می‌گیره.
🧪 اما داده‌های اعتبارسنجی (**Validation set**) برای ارزیابی عملکرد شبکه در زمان آموزش استفاده می‌شن.
اگر خطای اعتبارسنجی زیاد بشه در حالی که خطای آموزش کاهش پیدا کنه، یعنی شبکه دچار **overfitting** شده 🚨.

---

**سؤال 16: مراحل کلی ساخت یک شبکه عصبی چیست؟**
**پاسخ:**

1️⃣ تعیین ورودی‌ها و خروجی‌ها

2️⃣ نرمال‌سازی داده‌ها (مثلاً بین 1 و -1 🟰)

3️⃣ طراحی ساختار شبکه (تعداد نرون‌ها و لایه‌ها 🧱)

4️⃣ آموزش با داده‌های آموزشی 📚

5️⃣ اعتبارسنجی برای جلوگیری از overfitting ⚖️

6️⃣ تست نهایی عملکرد شبکه با داده‌های جدید 🧪

7️⃣ استفاده از مدل در پیش‌بینی واقعی 🔮

---

**سؤال 17: چه عواملی باعث موفقیت یا شکست آموزش یک شبکه می‌شوند؟**
**پاسخ:**

✅ عواملی که به **موفقیت** کمک می‌کنن:

* انتخاب درست تابع فعال‌سازی 📈
* ساختار مناسب شبکه (تعداد نرون و لایه 🧱)
* داده‌های آموزش کافی و متنوع 📊
* استفاده از الگوریتم‌های بهینه‌سازی مناسب مثل BP یا Gradient Descent 🧮

 
  ❌ عواملی که باعث **شکست** می‌شن:
* کم بودن داده یا نویز زیاد 📉
* استفاده از مدل بسیار بزرگ (overfitting 😬)
* انتخاب نادرست نرخ یادگیری یا تابع خطا ⚠️

---


**سؤال 18: شبکه‌ی **Hopfield** چه ویژگی منحصربه‌فردی دارد و چه کاربردی می‌تواند داشته باشد؟**
**پاسخ:**

شبکه Hopfield یک شبکه **بازگشتی (Recurrent)** است که نرون‌ها در آن به صورت کامل به هم متصل هستند 🔁.
ویژگی اصلی آن **حافظه انجمنی** است، یعنی می‌تواند یک الگوی ناقص را تکمیل کند 🧩.
کاربردش در بازشناسی الگو، بازسازی تصاویر، و حل مسائل بهینه‌سازی است 🧠💾.

---


**سؤال 19:منظور از آموزش **فعال (Active Learning)** چیست و چه مزیتی دارد؟**
**پاسخ:**

در آموزش فعال، **مدل خودش انتخاب می‌کند** که چه داده‌هایی برای یادگیری مفیدترند 🔍.
این روش باعث **افزایش کارایی** با استفاده از **کمترین تعداد برچسب‌ها** می‌شود 💡.
بیشتر در جاهایی کاربرد دارد که برچسب‌گذاری داده‌ها هزینه‌بر یا زمان‌بر است ⏳💰.

---

**سؤال 20: با توجه به فرمول Kolmogorov، اگر یک شبکه عصبی دارای 3 ورودی باشد، حداقل چند نرون در لایه پنهان نیاز دارد؟**
**پاسخ:**

طبق فرمول:
Hidden nodes = 2n + 1
\= 2 × 3 + 1 = **7**
بنابراین، حداقل 7 نرون در لایه پنهان نیاز است 🧠🔢.

---

**سؤال 21: با توجه به نمودار توابع Sigmoid، Tanh و ReLU، کدام‌یک برای شبکه‌های عمیق مناسب‌تر است و چرا؟**
**پاسخ:**

تابع **ReLU** در شبکه‌های عمیق عملکرد بهتری دارد چون:

* سرعت یادگیری را بالا می‌برد ⚡
* گرادیان را در لایه‌های بالا حفظ می‌کند 📈
* محاسبات ساده‌تری دارد (max(0,x)) 💡
  در حالی‌که Sigmoid و Tanh در لایه‌های زیاد ممکن است باعث **vanishing gradient** شوند 😵.

---



### **بخش دوم: تستی (چهارگزینه‌ای)**

**سؤال 1: اولین مدل ریاضی نرون مصنوعی توسط چه کسانی ارائه شد؟**  
A) جان هاپفیلد  
B) کالمن و مک‌کورد  
C) پیتس و مک‌کلاخ  
D) سایمون و مینسکی  

**پاسخ صحیح: C**  
**توضیح:** مدل ریاضی نرون توسط پیتس و مک‌کلاخ در سال 1943 معرفی شد. 🧠✨

---

**سؤال 2: وظیفه اصلی دندریت‌ها در نرون چیست؟**  
A) ارسال سیگنال  
B) پردازش اطلاعات  
C) دریافت سیگنال  
D) تنظیم وزن‌ها  

**پاسخ صحیح: C**  
**توضیح:** دندریت‌ها بخش ورودی نرون هستند که سیگنال‌ها را دریافت می‌کنند. ⚡️➡️🧠

---

**سؤال 3: تابع فعال‌سازی ReLU چگونه تعریف می‌شود؟**  
A) $f(x) = \tanh(x)$  
B) $f(x) = \frac{1}{1 + e^{-x}}$  
C) $f(x) = \max(0, x)$  
D) $f(x) = x^2$  

**پاسخ صحیح: C**  🔺⬅️📈

---

**سؤال 4: کدام نوع شبکه عصبی برای حل مشکل XOR معرفی شد؟**  
A) پرسپترون تک‌لایه  
B) شبکه بازخوردی  
C) شبکه چندلایه (MLP)  
D) RBF  

**پاسخ صحیح: C**  
**توضیح:** مشکل XOR توسط شبکه‌های چندلایه قابل حل است. ❌➡️✅✨

---

**سؤال 5: در مدل پرسپترون، خروجی چه زمانی 1 خواهد بود؟**  
A) وقتی مجموع ورودی‌ها منفی باشد  
B) وقتی وزن‌ها برابر صفر باشند  
C) وقتی net ≥ 0 باشد  
D) وقتی net < 0 باشد  

**پاسخ صحیح: C**  ➕➕ = ✅

---

**سؤال 6: کدام مورد جزو انواع شبکه‌های عصبی نیست؟**  
A) Hopfield  
B) Feedforward  
C) Kohonen  
D) Hadoop  

**پاسخ صحیح: D**  
**توضیح:** Hadoop یک چارچوب برای مدیریت داده است، نه شبکه عصبی. 🧠❌💾

---

**سؤال 7: در شبکه‌های عصبی، "Overfitting" به چه معناست؟**  
A) آموزش کم  
B) افزایش تعداد نرون‌ها  
C) یادگیری بیش از حد روی داده‌های آموزش  
D) عملکرد بالا در داده‌های جدید  

**پاسخ صحیح: C**  📚📚📚❌

---

**سؤال 8: چه بخشی از نرون وظیفه انتقال سیگنال به نرون‌های دیگر را دارد؟**  
A) دندریت  
B) آکسون  
C) سیناپس  
D) سوما  

**پاسخ صحیح: B**  
**توضیح:** آکسون سیگنال را از بدنه سلول به نرون‌های دیگر منتقل می‌کند. 🧠➡️📤

---

**سؤال 9: در شبکه‌های عصبی، چه عاملی بین نرون‌ها ارتباط برقرار می‌کند؟**  
A) لایه پنهان  
B) تابع فعال‌سازی  
C) سیناپس  
D) گرادیان نزولی  

**پاسخ صحیح: C**  
**توضیح:** سیناپس‌ها پل ارتباطی نرون‌ها هستند. 🔗🧠🔗

---

**سؤال 10: کدامیک از گزینه‌ها نوعی تابع فعال‌سازی نیست؟**  
A) ReLU  
B) Tanh  
C) Logistic  
D) Mean Square  

**پاسخ صحیح: D**  
**توضیح:** میانگین مربعات خطا یک تابع خطاست، نه تابع فعال‌سازی. ⚠️➖❌

--- 


**سؤال 11: اولین مدل ریاضی نرون مصنوعی توسط چه کسانی ارائه شد؟**  
A) جان هاپفیلد  
B) کالمن و مک‌کورد  
C) پیتس و مک‌کلاخ  
D) سایمون و مینسکی  


**پاسخ صحیح: C**  
**توضیح:** مدل ریاضی نرون توسط پیتس و مک‌کلاخ در سال 1943 معرفی شد. 🧠✨

---

**سؤال 12: وظیفه اصلی دندریت‌ها در نرون چیست؟**  
A) ارسال سیگنال  
B) پردازش اطلاعات  
C) دریافت سیگنال  
D) تنظیم وزن‌ها  

**پاسخ صحیح: C**  
**توضیح:** دندریت‌ها بخش ورودی نرون هستند که سیگنال‌ها را دریافت می‌کنند. ⚡️➡️🧠

---

**سؤال 13: تابع فعال‌سازی ReLU چگونه تعریف می‌شود؟**  
A) $f(x) = \tanh(x)$  
B) $f(x) = \frac{1}{1 + e^{-x}}$  
C) $f(x) = \max(0, x)$  
D) $f(x) = x^2$  

**پاسخ صحیح: C**  🔺⬅️📈

---

**سؤال 14: کدام نوع شبکه عصبی برای حل مشکل XOR معرفی شد؟**  
A) پرسپترون تک‌لایه  
B) شبکه بازخوردی  
C) شبکه چندلایه (MLP)  
D) RBF  

**پاسخ صحیح: C**  
**توضیح:** مشکل XOR توسط شبکه‌های چندلایه قابل حل است. ❌➡️✅✨

---

**سؤال 15: در مدل پرسپترون، خروجی چه زمانی 1 خواهد بود؟**  
A) وقتی مجموع ورودی‌ها منفی باشد  
B) وقتی وزن‌ها برابر صفر باشند  
C) وقتی net ≥ 0 باشد  
D) وقتی net < 0 باشد  

**پاسخ صحیح: C**  ➕➕ = ✅

---

**سؤال 16: کدام مورد جزو انواع شبکه‌های عصبی نیست؟**  
A) Hopfield  
B) Feedforward  
C) Kohonen  
D) Hadoop  

**پاسخ صحیح: D**  
**توضیح:** Hadoop یک چارچوب برای مدیریت داده است، نه شبکه عصبی. 🧠❌💾

---

**سؤال 17: در شبکه‌های عصبی، "Overfitting" به چه معناست؟**  
A) آموزش کم  
B) افزایش تعداد نرون‌ها  
C) یادگیری بیش از حد روی داده‌های آموزش  
D) عملکرد بالا در داده‌های جدید  

**پاسخ صحیح: C**  📚📚📚❌

---

**سؤال 18: چه بخشی از نرون وظیفه انتقال سیگنال به نرون‌های دیگر را دارد؟**  
A) دندریت  
B) آکسون  
C) سیناپس  
D) سوما  

**پاسخ صحیح: B**  
**توضیح:** آکسون سیگنال را از بدنه سلول به نرون‌های دیگر منتقل می‌کند. 🧠➡️📤

---

**سؤال 19: در شبکه‌های عصبی، چه عاملی بین نرون‌ها ارتباط برقرار می‌کند؟**  
A) لایه پنهان  
B) تابع فعال‌سازی  
C) سیناپس  
D) گرادیان نزولی  

**پاسخ صحیح: C**  
**توضیح:** سیناپس‌ها پل ارتباطی نرون‌ها هستند. 🔗🧠🔗

---

**سؤال 20: کدامیک از گزینه‌ها نوعی تابع فعال‌سازی نیست؟**  
A) ReLU  
B) Tanh  
C) Logistic  
D) Mean Square  

**پاسخ صحیح: D**  
**توضیح:** میانگین مربعات خطا یک تابع خطاست، نه تابع فعال‌سازی. ⚠️➖❌

--- 


**سؤال 21: شبکه‌ی عصبی **Kohonen** بر پایه کدام نوع یادگیری عمل می‌کند؟**  
A) یادگیری نظارت‌شده  
B) یادگیری بدون ناظر  
C) یادگیری تقویتی  
D) یادگیری نیمه‌نظارتی  


✅ **پاسخ صحیح: B**  
**توضیح:** شبکه‌های Kohonen یا SOM (Self Organizing Maps) از یادگیری بدون ناظر استفاده می‌کنند. 🧭

---

**سؤال 22: در روش آموزش **نیمه‌نظارتی (Semi-supervised)** چه نوع داده‌هایی استفاده می‌شود؟**  
A) فقط داده‌های برچسب‌دار  
B) فقط داده‌های بدون برچسب  
C) ترکیبی از برچسب‌دار و بدون برچسب  
D) فقط داده‌های نویزی  


✅ **پاسخ صحیح: C**  
**توضیح:** این روش ترکیبی از داده‌های دارای برچسب و بدون برچسب را برای آموزش استفاده می‌کند. 🔄📊

---

**سؤال 23: کدام مورد زیر یکی از **شرایط توقف** در الگوریتم Backpropagation است؟**  
A) وقتی تابع فعال‌سازی صفر شود  
B) وقتی نرخ یادگیری زیاد شود  
C) وقتی تعداد epochها به حد معین برسد  
D) وقتی همه وزن‌ها برابر شوند  


✅ **پاسخ صحیح: C**  
**توضیح:** یکی از شرایط رایج توقف در BP رسیدن به تعداد مشخصی از epochهاست. ⏳🛑

---
