

### سؤال 1:

### یادگیری ماشین به چند نوع اصلی تقسیم می‌شود؟

1. **یادگیری نظارت‌شده (Supervised Learning)**: 🤖
   - در این روش، داده‌ها شامل ورودی و خروجی (برچسب) هستند. مدل یاد می‌گیرد که از ورودی‌ها، خروجی درست را پیش‌بینی کند.
   - **مثال**: پیش‌بینی قیمت خانه بر اساس مساحت و مکان آن. 🏠💰

2. **یادگیری بدون نظارت (Unsupervised Learning)**: 🔍
   - در این روش، داده‌ها فقط ورودی دارند و هیچ برچسبی ندارند. مدل باید ساختار یا الگوی پنهان را در داده‌ها پیدا کند.
   - **مثال**: خوشه‌بندی مشتریان براساس رفتار خرید. 🛒👥

3. **یادگیری تقویتی (Reinforcement Learning)**: 🎮
   - در این روش، یک عامل (Agent) با محیط تعامل می‌کند، اقدامات مختلف انجام می‌دهد و بر اساس پاداش یا تنبیه، یاد می‌گیرد که بهترین تصمیم‌ها را در طول زمان بگیرد.
   - **مثال**: یادگیری بازی شطرنج یا رانندگی خودکار. ♟️🚗

---

### سؤال 2:

**تفاوت بین Classification (دسته‌بندی) و Regression (رگرسیون) چیست؟ با ذکر یک مثال برای هرکدام توضیح دهید.**

---

**پاسخ:**

در یادگیری ماشین:

1. **رگرسیون (Regression)**: 📈
   - برای پیش‌بینی مقادیر پیوسته و عددی استفاده می‌شود.
   - **مثال**: پیش‌بینی قیمت یک خانه بر اساس متراژ، تعداد اتاق‌ها و موقعیت مکانی. 🏠🔢

2. **دسته‌بندی (Classification)**: 📊
   - برای پیش‌بینی مقادیر گسسته و دسته‌ای استفاده می‌شود.
   - **مثال**: پیش‌بینی اینکه یک ایمیل "اسپم" است یا "عادی". 📧🚫

---

### سؤال 3:

**در یادگیری ماشین، مجموعه داده‌ها به چه بخش‌هایی تقسیم می‌شوند؟ هرکدام چه کاربردی دارند؟**

---

**پاسخ:**

مجموعه داده‌ها در یادگیری ماشین معمولاً به سه بخش تقسیم می‌شوند:

1. **Training Set (داده‌های آموزشی)**: 📚
   - برای آموزش مدل استفاده می‌شود. مدل از این داده‌ها یاد می‌گیرد.

2. **Validation Set (داده‌های اعتبارسنجی)**: 🔧
   - برای تنظیم پارامترها و انتخاب بهترین مدل استفاده می‌شود، بدون اینکه مدل آن‌ها را قبلاً دیده باشد.

3. **Test Set (داده‌های آزمایشی)**: 🧪
   - برای ارزیابی نهایی عملکرد مدل استفاده می‌شود. این داده‌ها فقط برای سنجش کیفیت مدل به کار می‌روند.

---

توضیحی **خلاصه، ساده و کاربردی** برای مفاهیم **Precision** و **Recall** آورده‌ام:

---

### 🎯 **Precision (دقت):**

🔸 یعنی از بین تمام مواردی که **مدل به عنوان مثبت (مثلاً "بیمار") پیش‌بینی کرده**،
چند درصدشان **واقعاً درست بوده‌اند؟**


✅ مثال:
اگر مدل بگه 10 نفر بیمارند، ولی فقط 7 نفر واقعاً بیمار باشند، precision = 70٪

---

### 🔍 **Recall (کامل بودن):**

🔸 یعنی از بین تمام مواردی که **واقعاً مثبت بوده‌اند** (مثلاً واقعاً "بیمار" بودند)،
مدل **چند درصد آن‌ها را درست تشخیص داده؟**

✅ مثال:
اگر 100 نفر واقعاً بیمار باشند و مدل فقط 80 نفر از آن‌ها را تشخیص دهد، recall = 80٪

---

### 🧠 جمع‌بندی ساده:

| مفهوم     | چه چیزی را می‌سنجد؟                         | مثال ساده                                    |
| --------- | ------------------------------------------- | -------------------------------------------- |
| Precision | پیش‌بینی‌های درست از بین همه‌ی مثبت‌های مدل | مدل چندتا از "مثبت‌هایی" که گفته، درست گفته؟ |
| Recall    | پیش‌بینی درست از بین همه‌ی مثبت‌های واقعی   | مدل چندتا از "واقعاً مثبت‌ها" را پیدا کرده؟  |

---




### سؤال 4:

**در جدول زیر، اطلاعاتی از پیش‌بینی بیماری در بیماران آورده شده است:**

| کلاس واقعی / پیش‌بینی‌شده | سرطان = بله | سرطان = خیر | جمع   |
| ------------------------- | ----------- | ----------- | ----- |
| سرطان = بله               | 90          | 210         | 300   |
| سرطان = خیر               | 140         | 9560        | 9700  |
| جمع                       | 230         | 9770        | 10000 |

**با استفاده از جدول بالا، مقادیر زیر را محاسبه کنید:**

1. **Accuracy** (دقت کلی) ✅
2. **Precision** (درست‌بودن پیش‌بینی‌ها برای سرطان = بله) 📏
3. **Recall** (کامل‌بودن پیش‌بینی‌ها برای سرطان = بله) 🔍
4. **F1-Score** (با فرض β = 1) 📊

---

**پاسخ:**

ابتدا مفاهیم را از جدول استخراج می‌کنیم:

- **TP (True Positive)** = 90
- **FN (False Negative)** = 210
- **FP (False Positive)** = 140
- **TN (True Negative)** = 9560
- **کل نمونه‌ها** = 10000


---


1. **Accuracy (دقت کلی):**

$$
Accuracy = \frac{TP + TN}{Total} = \frac{90 + 9560}{10000} = \frac{9650}{10000} = 0.965 = 96.5\%
$$

---

2. **Precision (دقت پیش‌بینی برای سرطان = بله):**

$$
Precision = \frac{TP}{TP + FP} = \frac{90}{90 + 140} = \frac{90}{230} ≈ 0.391 = 39.1\%
$$

---

3. **Recall (کامل بودن - نرخ تشخیص درست موارد مثبت):**

$$
Recall = \frac{TP}{TP + FN} = \frac{90}{90 + 210} = \frac{90}{300} = 0.3 = 30\%
$$

---

4. **F1-Score** (میانگین هارمونیک Precision و Recall):

$$
F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall} = 2 \times \frac{0.391 \times 0.3}{0.391 + 0.3} ≈ 2 \times \frac{0.1173}{0.691} ≈ 0.339 = 33.9\%
$$

---

**نتیجه‌گیری:**

* اگرچه **دقت کلی (Accuracy)** بالا است (96.5٪)، ولی **دقت تشخیص سرطان (Precision و Recall)** پایین است.
* این نشان می‌دهد که مدل ممکن است برای کاربردهای حساس مثل تشخیص سرطان **مناسب نباشد**، چون موارد زیادی از سرطان واقعی را شناسایی نمی‌کند (Recall پایین).
* در کاربردهای پزشکی، **Recall بالا اهمیت بیشتری دارد** تا مطمئن شویم بیمار واقعی نادیده گرفته نمی‌شود.😊

---

### ✳️ **سؤال 5:**

🧠 یکی از کاربردهای **دسته‌بندی (Classification)** در دنیای واقعی را نام ببرید و نحوه عملکرد مدل را به زبان ساده توضیح دهید.

---

### ✅ **پاسخ:**

یکی از کاربردهای رایج دسته‌بندی، **تشخیص ایمیل اسپم** است. 📧🚫

🔹 در این کاربرد، سیستم ایمیل باید تصمیم بگیرد که یک پیام:

* 📬 **ایمیل عادی (not spam)** است
* یا
* 🚫 **ایمیل اسپم (spam)** است

---

🔍 **نحوه عملکرد مدل به زبان ساده:**

1. ابتدا مدل با استفاده از مجموعه‌ای از ایمیل‌های قبلاً برچسب‌خورده آموزش می‌بیند (مثلاً این ایمیل‌ها اسپم هستند و آن‌ها نیستند). 🧾📚
2. ویژگی‌هایی مثل وجود کلمات مشکوک، تعداد لینک‌ها، فرستنده ناشناس و... بررسی می‌شود. 🕵️‍♂️🔗
3. سپس، مدل یاد می‌گیرد که بین ایمیل‌های عادی و اسپم تفاوت قائل شود.
4. حالا هر ایمیل جدید را مدل تحلیل می‌کند و تصمیم می‌گیرد:
   ➡️ آیا این ایمیل باید وارد inbox شود یا پوشه spam؟ 📥❌

---


### ✳️ **سؤال 6:**

📊 **مجموعه داده‌ها (Dataset)** چیست؟
👨‍💻 و منظور از **ویژگی‌ها (Attributes)** در یک مجموعه داده چه می‌باشد؟ با ذکر مثال توضیح دهید.

---

### ✅ **پاسخ:**

🗂️ **مجموعه داده (Dataset)**
به مجموعه‌ای از اطلاعات گفته می‌شود که شامل نمونه‌های مختلف از یک موضوع خاص هستند و برای آموزش یا ارزیابی مدل‌های یادگیری ماشین استفاده می‌شوند.

مثلاً مجموعه‌ای از اطلاعات مربوط به مشتریان بانک، شامل نام، سن، میزان درآمد، وضعیت تاهل و... یک مجموعه داده محسوب می‌شود. 🏦👥

---

🔍 **ویژگی‌ها (Attributes):**
ویژگی‌ها ستون‌های اطلاعاتی در یک مجموعه داده هستند که هر کدام، **یک خصوصیت از داده‌ها** را نشان می‌دهند.

📌 مثال:

| ID | سن | درآمد   | وضعیت تأهل | وام گرفته؟ |
| -- | -- | ------- | ---------- | ---------- |
| 1  | 28 | 70,000  | مجرد       | بله        |
| 2  | 45 | 120,000 | متأهل      | خیر        |

در جدول بالا:

* "سن"، "درآمد"، و "وضعیت تأهل" ویژگی (Attribute) هستند.
* هر ردیف (مانند ID=1) یک **نمونه (Instance)** است.


---
حتماً! در ادامه **سؤال شماره ۸** از مبحث **روش‌های نرمال‌سازی داده‌ها** همراه با پاسخ کامل و خلاصه به زبان فارسی آورده شده است:

---

### ✳️ **سؤال 7:**

📐 یکی از روش‌های نرمال‌سازی داده‌ها در یادگیری ماشین را نام ببرید و با ذکر فرمول و مثال ساده، نحوه کار آن را توضیح دهید.

---

### ✅ **پاسخ:**

یروش اول: **Min-Max Normalization (نرمال‌سازی حداقل-حداکثر)** است.

🔹 در این روش، مقدار اصلی ویژگی‌ها به بازه‌ای مشخص (مثلاً بین ۰ و ۱) منتقل می‌شود.

---

📌 **فرمول:**

$$
V' = \frac{V - min(A)}{max(A) - min(A)} \times (new_{max} - new_{min}) + new_{min}
$$

---

🧮 **مثال:**
فرض کنیم حقوق افراد در یک مجموعه بین ۱۲٬۰۰۰ تا ۹۸٬۰۰۰ دلار است.
اگر فردی ۷۳٬۶۰۰ دلار درآمد داشته باشد و بخواهیم مقدار نرمال‌شده آن را بین ۰ تا ۱ بیاوریم، خواهیم داشت:

$$
V' = \frac{73600 - 12000}{98000 - 12000} = \frac{61600}{86000} ≈ 0.716
$$

---

✨ در نتیجه، مقدار ۷۳٬۶۰۰ به **۰٫۷۱۶** تبدیل می‌شود. این کمک می‌کند تا داده‌ها مقیاس یکسانی داشته باشند و عملکرد مدل بهتر شود.

---


### ✳️ **روش دوم: نرمال‌سازی Z-Score (نمره Z)**

🔹 در این روش، داده‌ها بر اساس **میانگین (µ)** و **انحراف معیار (σ)** نرمال‌سازی می‌شوند.
این روش باعث می‌شود داده‌ها میانگین صفر و انحراف معیار ۱ داشته باشند.

---

📌 **فرمول:**

$$
V' = \frac{V - \mu_A}{\sigma_A}
$$

* $V$: مقدار اصلی ویژگی
* $\mu_A$: میانگین ویژگی
* $\sigma_A$: انحراف معیار ویژگی

---

🧮 **مثال:**

فرض کن میانگین درآمد = ۵۴٬۰۰۰ و انحراف معیار = ۱۶٬۰۰۰
اگر فردی درآمدی برابر ۷۳٬۶۰۰ دلار داشته باشد، مقدار نرمال‌شده با Z-Score به صورت زیر محاسبه می‌شود:

$$
V' = \frac{73600 - 54000}{16000} = \frac{19600}{16000} = 1.225
$$

---

✅ **نتیجه:**
مقدار ۷۳٬۶۰۰ به **۱٫۲۲۵** تبدیل می‌شود. این روش برای داده‌هایی با توزیع نرمال مناسب‌تر است و نسبت به Min-Max مقاوم‌تر در برابر داده‌های پرت (Outliers) می‌باشد.

---
